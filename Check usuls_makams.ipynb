{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Check usuls_makams.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/migperfer/AMPL-UPF-MSC/blob/master/Check%20usuls_makams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GTPoY6FR79v1"
      },
      "source": [
        "# Check if is executing on Google Colab\n",
        "If running on google colab download the repositories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FPhBcNYs79v7",
        "outputId": "29b787f5-455f-4a41-8a72-45cb441060dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  !git clone --recursive https://github.com/migperfer/AMPL-UPF-MSC\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AMPL-UPF-MSC'...\n",
            "remote: Enumerating objects: 145, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/145)\u001b[K\rremote: Counting objects:   1% (2/145)\u001b[K\rremote: Counting objects:   2% (3/145)\u001b[K\rremote: Counting objects:   3% (5/145)\u001b[K\rremote: Counting objects:   4% (6/145)\u001b[K\rremote: Counting objects:   5% (8/145)\u001b[K\rremote: Counting objects:   6% (9/145)\u001b[K\rremote: Counting objects:   7% (11/145)\u001b[K\rremote: Counting objects:   8% (12/145)\u001b[K\rremote: Counting objects:   9% (14/145)\u001b[K\rremote: Counting objects:  10% (15/145)\u001b[K\rremote: Counting objects:  11% (16/145)\u001b[K\rremote: Counting objects:  12% (18/145)\u001b[K\rremote: Counting objects:  13% (19/145)\u001b[K\rremote: Counting objects:  14% (21/145)\u001b[K\rremote: Counting objects:  15% (22/145)\u001b[K\rremote: Counting objects:  16% (24/145)\u001b[K\rremote: Counting objects:  17% (25/145)\u001b[K\rremote: Counting objects:  18% (27/145)\u001b[K\rremote: Counting objects:  19% (28/145)\u001b[K\rremote: Counting objects:  20% (29/145)\u001b[K\rremote: Counting objects:  21% (31/145)\u001b[K\rremote: Counting objects:  22% (32/145)\u001b[K\rremote: Counting objects:  23% (34/145)\u001b[K\rremote: Counting objects:  24% (35/145)\u001b[K\rremote: Counting objects:  25% (37/145)\u001b[K\rremote: Counting objects:  26% (38/145)\u001b[K\rremote: Counting objects:  27% (40/145)\u001b[K\rremote: Counting objects:  28% (41/145)\u001b[K\rremote: Counting objects:  29% (43/145)\u001b[K\rremote: Counting objects:  30% (44/145)\u001b[K\rremote: Counting objects:  31% (45/145)\u001b[K\rremote: Counting objects:  32% (47/145)\u001b[K\rremote: Counting objects:  33% (48/145)\u001b[K\rremote: Counting objects:  34% (50/145)\u001b[K\rremote: Counting objects:  35% (51/145)\u001b[K\rremote: Counting objects:  36% (53/145)\u001b[K\rremote: Counting objects:  37% (54/145)\u001b[K\rremote: Counting objects:  38% (56/145)\u001b[K\rremote: Counting objects:  39% (57/145)\u001b[K\rremote: Counting objects:  40% (58/145)\u001b[K\rremote: Counting objects:  41% (60/145)\u001b[K\rremote: Counting objects:  42% (61/145)\u001b[K\rremote: Counting objects:  43% (63/145)\u001b[K\rremote: Counting objects:  44% (64/145)\u001b[K\rremote: Counting objects:  45% (66/145)\u001b[K\rremote: Counting objects:  46% (67/145)\u001b[K\rremote: Counting objects:  47% (69/145)\u001b[K\rremote: Counting objects:  48% (70/145)\u001b[K\rremote: Counting objects:  49% (72/145)\u001b[K\rremote: Counting objects:  50% (73/145)\u001b[K\rremote: Counting objects:  51% (74/145)\u001b[K\rremote: Counting objects:  52% (76/145)\u001b[K\rremote: Counting objects:  53% (77/145)\u001b[K\rremote: Counting objects:  54% (79/145)\u001b[K\rremote: Counting objects:  55% (80/145)\u001b[K\rremote: Counting objects:  56% (82/145)\u001b[K\rremote: Counting objects:  57% (83/145)\u001b[K\rremote: Counting objects:  58% (85/145)\u001b[K\rremote: Counting objects:  59% (86/145)\u001b[K\rremote: Counting objects:  60% (87/145)\u001b[K\rremote: Counting objects:  61% (89/145)\u001b[K\rremote: Counting objects:  62% (90/145)\u001b[K\rremote: Counting objects:  63% (92/145)\u001b[K\rremote: Counting objects:  64% (93/145)\u001b[K\rremote: Counting objects:  65% (95/145)\u001b[K\rremote: Counting objects:  66% (96/145)\u001b[K\rremote: Counting objects:  67% (98/145)\u001b[K\rremote: Counting objects:  68% (99/145)\u001b[K\rremote: Counting objects:  69% (101/145)\u001b[K\rremote: Counting objects:  70% (102/145)\u001b[K\rremote: Counting objects:  71% (103/145)\u001b[K\rremote: Counting objects:  72% (105/145)\u001b[K\rremote: Counting objects:  73% (106/145)\u001b[K\rremote: Counting objects:  74% (108/145)\u001b[K\rremote: Counting objects:  75% (109/145)\u001b[K\rremote: Counting objects:  76% (111/145)\u001b[K\rremote: Counting objects:  77% (112/145)\u001b[K\rremote: Counting objects:  78% (114/145)\u001b[K\rremote: Counting objects:  79% (115/145)\u001b[K\rremote: Counting objects:  80% (116/145)\u001b[K\rremote: Counting objects:  81% (118/145)\u001b[K\rremote: Counting objects:  82% (119/145)\u001b[K\rremote: Counting objects:  83% (121/145)\u001b[K\rremote: Counting objects:  84% (122/145)\u001b[K\rremote: Counting objects:  85% (124/145)\u001b[K\rremote: Counting objects:  86% (125/145)\u001b[K\rremote: Counting objects:  87% (127/145)\u001b[K\rremote: Counting objects:  88% (128/145)\u001b[K\rremote: Counting objects:  89% (130/145)\u001b[K\rremote: Counting objects:  90% (131/145)\u001b[K\rremote: Counting objects:  91% (132/145)\u001b[K\rremote: Counting objects:  92% (134/145)\u001b[K\rremote: Counting objects:  93% (135/145)\u001b[K\rremote: Counting objects:  94% (137/145)\u001b[K\rremote: Counting objects:  95% (138/145)\u001b[K\rremote: Counting objects:  96% (140/145)\u001b[K\rremote: Counting objects:  97% (141/145)\u001b[K\rremote: Counting objects:  98% (143/145)\u001b[K\rremote: Counting objects:  99% (144/145)\u001b[K\rremote: Counting objects: 100% (145/145)\u001b[K\rremote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 145 (delta 67), reused 122 (delta 51), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (145/145), 111.47 KiB | 704.00 KiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n",
            "Submodule 'SymbTr' (https://github.com/MTG/SymbTr) registered for path 'SymbTr'\n",
            "Cloning into '/content/AMPL-UPF-MSC/SymbTr'...\n",
            "remote: Enumerating objects: 51780, done.        \n",
            "remote: Total 51780 (delta 0), reused 0 (delta 0), pack-reused 51780        \n",
            "Receiving objects: 100% (51780/51780), 100.45 MiB | 16.93 MiB/s, done.\n",
            "Resolving deltas: 100% (42440/42440), done.\n",
            "Submodule path 'SymbTr': checked out 'dbc9b26d21f73c8c229f0565ace47a3318ba2c4f'\n",
            "Submodule 'SymbTr-extras' (https://github.com/MTG/SymbTr-extras.git) registered for path 'SymbTr/SymbTr-extras'\n",
            "Submodule 'SymbTr-pdf' (https://github.com/MTG/SymbTr-pdf.git) registered for path 'SymbTr/SymbTr-pdf'\n",
            "Cloning into '/content/AMPL-UPF-MSC/SymbTr/SymbTr-extras'...\n",
            "remote: Enumerating objects: 595, done.        \n",
            "remote: Total 595 (delta 0), reused 0 (delta 0), pack-reused 595        \n",
            "Receiving objects: 100% (595/595), 506.41 KiB | 1.44 MiB/s, done.\n",
            "Resolving deltas: 100% (379/379), done.\n",
            "Cloning into '/content/AMPL-UPF-MSC/SymbTr/SymbTr-pdf'...\n",
            "remote: Enumerating objects: 3598, done.        \n",
            "remote: Total 3598 (delta 0), reused 0 (delta 0), pack-reused 3598        \n",
            "Receiving objects: 100% (3598/3598), 230.09 MiB | 38.92 MiB/s, done.\n",
            "Resolving deltas: 100% (795/795), done.\n",
            "Submodule path 'SymbTr/SymbTr-extras': checked out 'dcaad13d9e1ab35583042276fa9c434ae153cc5b'\n",
            "Submodule path 'SymbTr/SymbTr-pdf': checked out '1e8b36dfb1c543ea1be059cf04d5a2952b74ca2e'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AkjDrcqD79wT"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pigB1EWs79wZ",
        "colab": {}
      },
      "source": [
        "from music21 import *\n",
        "from music21.note import Note as noteclass\n",
        "from music21.chord import Chord as chordclass\n",
        "from music21.meter import TimeSignature as tsclass\n",
        "import os, glob, math\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ptf1XNm379wr"
      },
      "source": [
        "# Creation of Usul related objects\n",
        "## Definition of the UsulStroke and Usul classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r3bTE_Kw79ww",
        "colab": {}
      },
      "source": [
        "class UsulStroke:\n",
        "  def __init__(self, mnote, stroke, barduration):    \n",
        "    self.stroketype = stroke.content\n",
        "    self.duration = mnote.duration.quarterLength\n",
        "    self.offset = mnote.beat\n",
        "    self.barduration = barduration\n",
        "    self.compatoffset = float(str(float((mnote.beat - 1)/barduration))[:4])\n",
        "    if isinstance(mnote, chordclass):\n",
        "      self.hand = \"both\"\n",
        "    elif mnote.pitch.name == \"F\":\n",
        "      self.hand = \"right\"\n",
        "    elif mnote.pitch.name == \"D\":\n",
        "      self.hand = \"left\"\n",
        "    else:\n",
        "      self.hand = \"unknown\"\n",
        "\n",
        "  def __repr__(self):\n",
        "    return \"UsulStroke\"\n",
        "\n",
        "  def __str__(self):\n",
        "    return \"Stroke:%s, Duration:%s, Hand:%s, Offset:%s\" % (self.stroketype, self.duration, self.hand, self.compatoffset)\n",
        "\n",
        "class Usul:\n",
        "  def __init__(self, usulname, strokes, nbeats):\n",
        "    self.nbeats = nbeats\n",
        "    self.usul = usulname\n",
        "    self.strokes = strokes\n",
        "\n",
        "  @classmethod\n",
        "  def usul_from_file(cls, file):\n",
        "    nbeats = 0\n",
        "    score = converter.parse(file)\n",
        "    rhythm = score.getElementsByClass('Part')[0].getElementsByClass('Measure')[0]\n",
        "    notes = []\n",
        "    for element in rhythm:\n",
        "      if isinstance(element, (noteclass, chordclass)):\n",
        "        notes.append(element)\n",
        "      if isinstance(element, (tsclass)):\n",
        "        nbeats = element.beatCount\n",
        "        \n",
        "    strokes = rhythm.getElementsByClass('TextExpression')\n",
        "    usul_name = file.split('/')[-1].split('.mxl')[0].lower().replace('_', ' ')\n",
        "    strokes_list = []\n",
        "    for note in range(len(notes)):\n",
        "      strk = UsulStroke(notes[note], strokes[note], nbeats)\n",
        "      strokes_list.append(strk)\n",
        "    return cls(usul_name, strokes_list, nbeats)\n",
        "\n",
        "\n",
        "  def __iter__(self):\n",
        "    self.index = 0\n",
        "    return self\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "        return self.strokes[idx]\n",
        "\n",
        "  def __next__(self):\n",
        "    if self.index < len(self.strokes):\n",
        "      idx = self.index\n",
        "      self.index += 1\n",
        "      return self.strokes[idx]\n",
        "    else:\n",
        "      raise StopIteration\n",
        "\n",
        "  def _repr__(self):\n",
        "    return \"Usul\"\n",
        "  \n",
        "  def __str__(self):\n",
        "    return \"Usul Object: %s\" % (self.usul)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q-q72Ozi79w5"
      },
      "source": [
        "## Load all existing usuls with the classes created in last cell\n",
        "\n",
        "We load all the usuls possible (the ones for which we have the scores), into the *usul_dict* dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Z4yv3wA79w7",
        "colab": {}
      },
      "source": [
        "if IN_COLAB:\n",
        "    usuls_files_list = glob.glob('./AMPL-UPF-MSC/scores/mxl/*.mxl')\n",
        "else:\n",
        "    usuls_files_list = glob.glob('./scores/mxl/*.mxl')\n",
        "\n",
        "usuls_dict = {}\n",
        "for usul_file in usuls_files_list:\n",
        "  usul_name = usul_file.split('/')[-1].split('.mxl')[0].lower().replace('_', ' ')\n",
        "  if '\\\\' in usul_name:  # Windows use \\ instead of /\n",
        "        usul_name = usul_name.split('\\\\')[-1]\n",
        "  usuls_dict[usul_name] = Usul.usul_from_file(usul_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nPzngwqJ79xH"
      },
      "source": [
        "## Load define makams functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B3sh0pIv79xJ",
        "colab": {}
      },
      "source": [
        "usuldict = {'sofyan':0,'duyek':1,'raksaksagi':2,'cenber':3,'hafif':4,'devrikebir':5,'muhammes':6,'turkaksagi':7,'oynak':8,'havi':9,'aksak':10,'yuruksemai':11,'berefsan':12,'aksaksemai':13,'fahte':14,'semai':15,'cifteduyek':16,'evfer':17}\n",
        "makamlist = ['hicaz','rast','nihavent','ussak','segah','huseyni','huzzam','mahur','kurdilihicazkar','muhayyer']\n",
        "makamdict = {makamlist[i]:i for i in range(len(makamlist))}\n",
        "\n",
        "rast = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'D5','Lead':'F4#'}\n",
        "huseyni = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'E5','Lead':'G4'}\n",
        "muhayyer = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'A5','sDom':'E5','Lead':'G4'}\n",
        "ussak = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'D5','Lead':'G4'}\n",
        "hicaz = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'D5','Lead':'G4'}\n",
        "huzzam = {'B':1,'C':2,'D':3,'E':4,'F':5, 'G':6,'A':7,'Dom':'D5','Lead':'A4#'}\n",
        "kurdilihicazkar = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'G5','Lead':'F4'} \n",
        "nihavent = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'D5','Lead':'F4#'}\n",
        "segah = {'B':1,'C':2,'D':3,'E':4,'F':5, 'G':6,'A':7,'Dom':'D5','Lead':'A4#'}\n",
        "mahur = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'G5','Lead':'F4#'}\n",
        "\n",
        "if IN_COLAB:\n",
        "    folder = 'AMPL-UPF-MSC/SymbTr/txt/'\n",
        "else:\n",
        "    folder = 'SymbTr/txt/'\n",
        "\n",
        "allScores = os.listdir(folder)\n",
        "\n",
        "def getDegree(note,makam):\n",
        "    significance = None\n",
        "    degree = eval(makam)[note[0]]\n",
        "    if degree == 1:\n",
        "        significance = 'Tonic'\n",
        "    if note[:2] == eval(makam)['Dom']:\n",
        "        significance = 'Dominant'\n",
        "    if note[:2] == eval(makam)['Lead']:\n",
        "        significance = 'Leading'    \n",
        "    return degree,significance\n",
        "\n",
        "def getbars(makam,usul):\n",
        "    bars = []\n",
        "    bar = []\n",
        "    for file in allScores:\n",
        "        mak,_,us = file.split('--')[:3]\n",
        "        \n",
        "        if (mak != makam) or (us != usul):\n",
        "            continue\n",
        "        \n",
        "        with open(folder + file, encoding=\"utf8\") as scoretxt:\n",
        "            txtlines = scoretxt.read().split('\\n')\n",
        "        for i in range(2,len(txtlines)-1):\n",
        "            if int(txtlines[i].split('\\t')[1])==51: # possible usul change, leave the rest\n",
        "                break\n",
        "            if int(txtlines[i].split('\\t')[6])>0:\n",
        "                dur = int(txtlines[i].split('\\t')[6])/int(txtlines[i].split('\\t')[7])\n",
        "                notename = txtlines[i].split('\\t')[3]\n",
        "                degree, significance = getDegree(notename,mak)\n",
        "                offset = txtlines[i].split('\\t')[-1]     \n",
        "                bar.append([offset,dur,notename,degree,significance])\n",
        "                if float(offset).is_integer():\n",
        "                    bars.append(bar)\n",
        "                    bar = []\n",
        "    return bars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K9zYK8E379xS"
      },
      "source": [
        "## Function to analyze a makam using an usul object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x4s6qrPZ79xW",
        "colab": {}
      },
      "source": [
        "def analyze_makam(makam_name, usul_name):\n",
        "    usul_part = usul_name.replace(\"ü\", \"u\").replace(\" \", \"\").replace(\"ç\",\"c\").replace(\"ğ\",\"g\").replace(\"ş\",\"s\").replace(\"-\",\"\")\n",
        "    makam_part = makamdict[makam_name]\n",
        "    makam = getbars(makam_name, usul_part)\n",
        "    if makam == []:\n",
        "      raise ValueError(\"Can't load makam %s-%s\" % (makam_name, usul_part))\n",
        "    usul = usuls_dict[usul_name]\n",
        "    coincidences = []\n",
        "    usul_onsets = []\n",
        "    for stroke in usul:\n",
        "        usul_onsets.append(stroke.compatoffset)  # Get the position of every stroke in this\n",
        "    onsets_indx = dict((k,i) for i,k in enumerate(usul_onsets))  # Store the index of every beat position\n",
        "    for bar in makam:\n",
        "        for note in bar:\n",
        "            beat, bar = math.modf(float(note[0]))  # Split the integer part and the decimal one\n",
        "            beat = beat # Substract the duration, to get the beat position\n",
        "            beat = float(str(beat)[:4])  # Limit to 4 the number of decimals\n",
        "\n",
        "            if beat in usul_onsets:\n",
        "                coinc_stroke = usul[onsets_indx[beat]]  # Get coincident stroke\n",
        "                coincidence = {'hand': coinc_stroke.hand, 'duration': coinc_stroke.duration, 'stroke': coinc_stroke.stroketype,\n",
        "                               'note_name': note[2], 'note_degree': note[3], 'note_significance': note[4], 'makam': makam_name, 'usul': usul_name}\n",
        "                coincidences.append(coincidence)\n",
        "    coincidences = pd.DataFrame(coincidences)\n",
        "    return coincidences\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wgBdQMtwEQKT"
      },
      "source": [
        "## Analyze the scores\n",
        "Analyze the scores and save them into a folder called _csv-data_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aFflfzmT_h5R",
        "outputId": "f1c189f5-1c4c-4fc7-a816-9e026bf8afde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if not os.path.isdir('csv-data/'):\n",
        "  os.mkdir('csv-data/')\n",
        "import gc\n",
        "empty_ones = []\n",
        "broken_ones = []\n",
        "for usul_key in usuls_dict.keys():\n",
        "  for makam_key in makamdict.keys():\n",
        "    print(\"Analizing %s-%s\" % (usul_key, makam_key))\n",
        "    try:\n",
        "      results = analyze_makam(makam_key, usul_key)\n",
        "    except ValueError:\n",
        "      print(\"\\tBroken %s, %s\" % (makam_key, usul_key))\n",
        "      broken_ones.append(\"%s, %s\" % (makam_key, usul_key))\n",
        "      continue\n",
        "    if not results.empty:\n",
        "      results.to_csv('csv-data/%s-%s.csv' % (usul_key, makam_key))\n",
        "      print(\"\\tAnalyzed %s-%s\" % (usul_key, makam_key))\n",
        "    else:\n",
        "      print(\"\\tEmpty: \", usul_key, makam_key)\n",
        "      empty_ones.append(\"%s-%s\" % (usul_key, makam_key))\n",
        "  gc.collect()\n",
        "with open('csv-data/empty_ones.txt', 'w', encoding=\"utf8\") as file:\n",
        "  for empty in empty_ones:\n",
        "    file.write(\"%s\\n\" % empty)\n",
        "with open('csv-data/broken_ones.txt', 'w', encoding=\"utf8\") as file:\n",
        "  for broken in broken_ones:\n",
        "    file.write(\"%s\\n\" % broken)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analizing türk aksaği-hicaz\n",
            "\tAnalyzed türk aksaği-hicaz\n",
            "Analizing türk aksaği-rast\n",
            "\tAnalyzed türk aksaği-rast\n",
            "Analizing türk aksaği-nihavent\n",
            "\tAnalyzed türk aksaği-nihavent\n",
            "Analizing türk aksaği-ussak\n",
            "\tAnalyzed türk aksaği-ussak\n",
            "Analizing türk aksaği-segah\n",
            "\tAnalyzed türk aksaği-segah\n",
            "Analizing türk aksaği-huseyni\n",
            "\tAnalyzed türk aksaği-huseyni\n",
            "Analizing türk aksaği-huzzam\n",
            "\tAnalyzed türk aksaği-huzzam\n",
            "Analizing türk aksaği-mahur\n",
            "\tBroken mahur, türk aksaği\n",
            "Analizing türk aksaği-kurdilihicazkar\n",
            "\tAnalyzed türk aksaği-kurdilihicazkar\n",
            "Analizing türk aksaği-muhayyer\n",
            "\tAnalyzed türk aksaği-muhayyer\n",
            "Analizing çifte düyek-hicaz\n",
            "\tBroken hicaz, çifte düyek\n",
            "Analizing çifte düyek-rast\n",
            "\tAnalyzed çifte düyek-rast\n",
            "Analizing çifte düyek-nihavent\n",
            "\tBroken nihavent, çifte düyek\n",
            "Analizing çifte düyek-ussak\n",
            "\tBroken ussak, çifte düyek\n",
            "Analizing çifte düyek-segah\n",
            "\tBroken segah, çifte düyek\n",
            "Analizing çifte düyek-huseyni\n",
            "\tAnalyzed çifte düyek-huseyni\n",
            "Analizing çifte düyek-huzzam\n",
            "\tBroken huzzam, çifte düyek\n",
            "Analizing çifte düyek-mahur\n",
            "\tBroken mahur, çifte düyek\n",
            "Analizing çifte düyek-kurdilihicazkar\n",
            "\tBroken kurdilihicazkar, çifte düyek\n",
            "Analizing çifte düyek-muhayyer\n",
            "\tBroken muhayyer, çifte düyek\n",
            "Analizing semai-hicaz\n",
            "\tAnalyzed semai-hicaz\n",
            "Analizing semai-rast\n",
            "\tAnalyzed semai-rast\n",
            "Analizing semai-nihavent\n",
            "\tAnalyzed semai-nihavent\n",
            "Analizing semai-ussak\n",
            "\tAnalyzed semai-ussak\n",
            "Analizing semai-segah\n",
            "\tAnalyzed semai-segah\n",
            "Analizing semai-huseyni\n",
            "\tAnalyzed semai-huseyni\n",
            "Analizing semai-huzzam\n",
            "\tAnalyzed semai-huzzam\n",
            "Analizing semai-mahur\n",
            "\tAnalyzed semai-mahur\n",
            "Analizing semai-kurdilihicazkar\n",
            "\tAnalyzed semai-kurdilihicazkar\n",
            "Analizing semai-muhayyer\n",
            "\tAnalyzed semai-muhayyer\n",
            "Analizing evfer-hicaz\n",
            "\tAnalyzed evfer-hicaz\n",
            "Analizing evfer-rast\n",
            "\tAnalyzed evfer-rast\n",
            "Analizing evfer-nihavent\n",
            "\tBroken nihavent, evfer\n",
            "Analizing evfer-ussak\n",
            "\tAnalyzed evfer-ussak\n",
            "Analizing evfer-segah\n",
            "\tBroken segah, evfer\n",
            "Analizing evfer-huseyni\n",
            "\tAnalyzed evfer-huseyni\n",
            "Analizing evfer-huzzam\n",
            "\tBroken huzzam, evfer\n",
            "Analizing evfer-mahur\n",
            "\tAnalyzed evfer-mahur\n",
            "Analizing evfer-kurdilihicazkar\n",
            "\tAnalyzed evfer-kurdilihicazkar\n",
            "Analizing evfer-muhayyer\n",
            "\tBroken muhayyer, evfer\n",
            "Analizing havi-hicaz\n",
            "\tBroken hicaz, havi\n",
            "Analizing havi-rast\n",
            "\tBroken rast, havi\n",
            "Analizing havi-nihavent\n",
            "\tBroken nihavent, havi\n",
            "Analizing havi-ussak\n",
            "\tBroken ussak, havi\n",
            "Analizing havi-segah\n",
            "\tBroken segah, havi\n",
            "Analizing havi-huseyni\n",
            "\tAnalyzed havi-huseyni\n",
            "Analizing havi-huzzam\n",
            "\tBroken huzzam, havi\n",
            "Analizing havi-mahur\n",
            "\tBroken mahur, havi\n",
            "Analizing havi-kurdilihicazkar\n",
            "\tBroken kurdilihicazkar, havi\n",
            "Analizing havi-muhayyer\n",
            "\tBroken muhayyer, havi\n",
            "Analizing hafif-hicaz\n",
            "\tBroken hicaz, hafif\n",
            "Analizing hafif-rast\n",
            "\tAnalyzed hafif-rast\n",
            "Analizing hafif-nihavent\n",
            "\tAnalyzed hafif-nihavent\n",
            "Analizing hafif-ussak\n",
            "\tAnalyzed hafif-ussak\n",
            "Analizing hafif-segah\n",
            "\tAnalyzed hafif-segah\n",
            "Analizing hafif-huseyni\n",
            "\tBroken huseyni, hafif\n",
            "Analizing hafif-huzzam\n",
            "\tBroken huzzam, hafif\n",
            "Analizing hafif-mahur\n",
            "\tAnalyzed hafif-mahur\n",
            "Analizing hafif-kurdilihicazkar\n",
            "\tBroken kurdilihicazkar, hafif\n",
            "Analizing hafif-muhayyer\n",
            "\tBroken muhayyer, hafif\n",
            "Analizing aksak semai-hicaz\n",
            "\tAnalyzed aksak semai-hicaz\n",
            "Analizing aksak semai-rast\n",
            "\tAnalyzed aksak semai-rast\n",
            "Analizing aksak semai-nihavent\n",
            "\tAnalyzed aksak semai-nihavent\n",
            "Analizing aksak semai-ussak\n",
            "\tAnalyzed aksak semai-ussak\n",
            "Analizing aksak semai-segah\n",
            "\tAnalyzed aksak semai-segah\n",
            "Analizing aksak semai-huseyni\n",
            "\tAnalyzed aksak semai-huseyni\n",
            "Analizing aksak semai-huzzam\n",
            "\tAnalyzed aksak semai-huzzam\n",
            "Analizing aksak semai-mahur\n",
            "\tAnalyzed aksak semai-mahur\n",
            "Analizing aksak semai-kurdilihicazkar\n",
            "\tAnalyzed aksak semai-kurdilihicazkar\n",
            "Analizing aksak semai-muhayyer\n",
            "\tAnalyzed aksak semai-muhayyer\n",
            "Analizing aksak-hicaz\n",
            "\tAnalyzed aksak-hicaz\n",
            "Analizing aksak-rast\n",
            "\tAnalyzed aksak-rast\n",
            "Analizing aksak-nihavent\n",
            "\tAnalyzed aksak-nihavent\n",
            "Analizing aksak-ussak\n",
            "\tAnalyzed aksak-ussak\n",
            "Analizing aksak-segah\n",
            "\tAnalyzed aksak-segah\n",
            "Analizing aksak-huseyni\n",
            "\tAnalyzed aksak-huseyni\n",
            "Analizing aksak-huzzam\n",
            "\tAnalyzed aksak-huzzam\n",
            "Analizing aksak-mahur\n",
            "\tAnalyzed aksak-mahur\n",
            "Analizing aksak-kurdilihicazkar\n",
            "\tAnalyzed aksak-kurdilihicazkar\n",
            "Analizing aksak-muhayyer\n",
            "\tAnalyzed aksak-muhayyer\n",
            "Analizing düyek-hicaz\n",
            "\tAnalyzed düyek-hicaz\n",
            "Analizing düyek-rast\n",
            "\tAnalyzed düyek-rast\n",
            "Analizing düyek-nihavent\n",
            "\tAnalyzed düyek-nihavent\n",
            "Analizing düyek-ussak\n",
            "\tAnalyzed düyek-ussak\n",
            "Analizing düyek-segah\n",
            "\tAnalyzed düyek-segah\n",
            "Analizing düyek-huseyni\n",
            "\tAnalyzed düyek-huseyni\n",
            "Analizing düyek-huzzam\n",
            "\tAnalyzed düyek-huzzam\n",
            "Analizing düyek-mahur\n",
            "\tAnalyzed düyek-mahur\n",
            "Analizing düyek-kurdilihicazkar\n",
            "\tAnalyzed düyek-kurdilihicazkar\n",
            "Analizing düyek-muhayyer\n",
            "\tAnalyzed düyek-muhayyer\n",
            "Analizing muhammes-hicaz\n",
            "\tBroken hicaz, muhammes\n",
            "Analizing muhammes-rast\n",
            "\tAnalyzed muhammes-rast\n",
            "Analizing muhammes-nihavent\n",
            "\tBroken nihavent, muhammes\n",
            "Analizing muhammes-ussak\n",
            "\tBroken ussak, muhammes\n",
            "Analizing muhammes-segah\n",
            "\tBroken segah, muhammes\n",
            "Analizing muhammes-huseyni\n",
            "\tAnalyzed muhammes-huseyni\n",
            "Analizing muhammes-huzzam\n",
            "\tAnalyzed muhammes-huzzam\n",
            "Analizing muhammes-mahur\n",
            "\tAnalyzed muhammes-mahur\n",
            "Analizing muhammes-kurdilihicazkar\n",
            "\tAnalyzed muhammes-kurdilihicazkar\n",
            "Analizing muhammes-muhayyer\n",
            "\tAnalyzed muhammes-muhayyer\n",
            "Analizing sofyan-hicaz\n",
            "\tAnalyzed sofyan-hicaz\n",
            "Analizing sofyan-rast\n",
            "\tAnalyzed sofyan-rast\n",
            "Analizing sofyan-nihavent\n",
            "\tAnalyzed sofyan-nihavent\n",
            "Analizing sofyan-ussak\n",
            "\tAnalyzed sofyan-ussak\n",
            "Analizing sofyan-segah\n",
            "\tAnalyzed sofyan-segah\n",
            "Analizing sofyan-huseyni\n",
            "\tAnalyzed sofyan-huseyni\n",
            "Analizing sofyan-huzzam\n",
            "\tAnalyzed sofyan-huzzam\n",
            "Analizing sofyan-mahur\n",
            "\tAnalyzed sofyan-mahur\n",
            "Analizing sofyan-kurdilihicazkar\n",
            "\tAnalyzed sofyan-kurdilihicazkar\n",
            "Analizing sofyan-muhayyer\n",
            "\tAnalyzed sofyan-muhayyer\n",
            "Analizing çenber-hicaz\n",
            "\tBroken hicaz, çenber\n",
            "Analizing çenber-rast\n",
            "\tAnalyzed çenber-rast\n",
            "Analizing çenber-nihavent\n",
            "\tBroken nihavent, çenber\n",
            "Analizing çenber-ussak\n",
            "\tAnalyzed çenber-ussak\n",
            "Analizing çenber-segah\n",
            "\tBroken segah, çenber\n",
            "Analizing çenber-huseyni\n",
            "\tAnalyzed çenber-huseyni\n",
            "Analizing çenber-huzzam\n",
            "\tBroken huzzam, çenber\n",
            "Analizing çenber-mahur\n",
            "\tBroken mahur, çenber\n",
            "Analizing çenber-kurdilihicazkar\n",
            "\tBroken kurdilihicazkar, çenber\n",
            "Analizing çenber-muhayyer\n",
            "\tBroken muhayyer, çenber\n",
            "Analizing berefşan-hicaz\n",
            "\tBroken hicaz, berefşan\n",
            "Analizing berefşan-rast\n",
            "\tBroken rast, berefşan\n",
            "Analizing berefşan-nihavent\n",
            "\tBroken nihavent, berefşan\n",
            "Analizing berefşan-ussak\n",
            "\tBroken ussak, berefşan\n",
            "Analizing berefşan-segah\n",
            "\tBroken segah, berefşan\n",
            "Analizing berefşan-huseyni\n",
            "\tAnalyzed berefşan-huseyni\n",
            "Analizing berefşan-huzzam\n",
            "\tBroken huzzam, berefşan\n",
            "Analizing berefşan-mahur\n",
            "\tBroken mahur, berefşan\n",
            "Analizing berefşan-kurdilihicazkar\n",
            "\tBroken kurdilihicazkar, berefşan\n",
            "Analizing berefşan-muhayyer\n",
            "\tBroken muhayyer, berefşan\n",
            "Analizing fahte-hicaz\n",
            "\tAnalyzed fahte-hicaz\n",
            "Analizing fahte-rast\n",
            "\tBroken rast, fahte\n",
            "Analizing fahte-nihavent\n",
            "\tAnalyzed fahte-nihavent\n",
            "Analizing fahte-ussak\n",
            "\tBroken ussak, fahte\n",
            "Analizing fahte-segah\n",
            "\tBroken segah, fahte\n",
            "Analizing fahte-huseyni\n",
            "\tBroken huseyni, fahte\n",
            "Analizing fahte-huzzam\n",
            "\tAnalyzed fahte-huzzam\n",
            "Analizing fahte-mahur\n",
            "\tBroken mahur, fahte\n",
            "Analizing fahte-kurdilihicazkar\n",
            "\tBroken kurdilihicazkar, fahte\n",
            "Analizing fahte-muhayyer\n",
            "\tBroken muhayyer, fahte\n",
            "Analizing raks aksaği-hicaz\n",
            "\tAnalyzed raks aksaği-hicaz\n",
            "Analizing raks aksaği-rast\n",
            "\tBroken rast, raks aksaği\n",
            "Analizing raks aksaği-nihavent\n",
            "\tBroken nihavent, raks aksaği\n",
            "Analizing raks aksaği-ussak\n",
            "\tAnalyzed raks aksaği-ussak\n",
            "Analizing raks aksaği-segah\n",
            "\tAnalyzed raks aksaği-segah\n",
            "Analizing raks aksaği-huseyni\n",
            "\tAnalyzed raks aksaği-huseyni\n",
            "Analizing raks aksaği-huzzam\n",
            "\tBroken huzzam, raks aksaği\n",
            "Analizing raks aksaği-mahur\n",
            "\tBroken mahur, raks aksaği\n",
            "Analizing raks aksaği-kurdilihicazkar\n",
            "\tBroken kurdilihicazkar, raks aksaği\n",
            "Analizing raks aksaği-muhayyer\n",
            "\tAnalyzed raks aksaği-muhayyer\n",
            "Analizing yürük semai-hicaz\n",
            "\tAnalyzed yürük semai-hicaz\n",
            "Analizing yürük semai-rast\n",
            "\tAnalyzed yürük semai-rast\n",
            "Analizing yürük semai-nihavent\n",
            "\tAnalyzed yürük semai-nihavent\n",
            "Analizing yürük semai-ussak\n",
            "\tAnalyzed yürük semai-ussak\n",
            "Analizing yürük semai-segah\n",
            "\tAnalyzed yürük semai-segah\n",
            "Analizing yürük semai-huseyni\n",
            "\tAnalyzed yürük semai-huseyni\n",
            "Analizing yürük semai-huzzam\n",
            "\tAnalyzed yürük semai-huzzam\n",
            "Analizing yürük semai-mahur\n",
            "\tAnalyzed yürük semai-mahur\n",
            "Analizing yürük semai-kurdilihicazkar\n",
            "\tAnalyzed yürük semai-kurdilihicazkar\n",
            "Analizing yürük semai-muhayyer\n",
            "\tAnalyzed yürük semai-muhayyer\n",
            "Analizing devr-i kebir-hicaz\n",
            "\tBroken hicaz, devr-i kebir\n",
            "Analizing devr-i kebir-rast\n",
            "\tAnalyzed devr-i kebir-rast\n",
            "Analizing devr-i kebir-nihavent\n",
            "\tAnalyzed devr-i kebir-nihavent\n",
            "Analizing devr-i kebir-ussak\n",
            "\tAnalyzed devr-i kebir-ussak\n",
            "Analizing devr-i kebir-segah\n",
            "\tAnalyzed devr-i kebir-segah\n",
            "Analizing devr-i kebir-huseyni\n",
            "\tAnalyzed devr-i kebir-huseyni\n",
            "Analizing devr-i kebir-huzzam\n",
            "\tAnalyzed devr-i kebir-huzzam\n",
            "Analizing devr-i kebir-mahur\n",
            "\tAnalyzed devr-i kebir-mahur\n",
            "Analizing devr-i kebir-kurdilihicazkar\n",
            "\tBroken kurdilihicazkar, devr-i kebir\n",
            "Analizing devr-i kebir-muhayyer\n",
            "\tAnalyzed devr-i kebir-muhayyer\n",
            "Analizing oynak-hicaz\n",
            "\tBroken hicaz, oynak\n",
            "Analizing oynak-rast\n",
            "\tAnalyzed oynak-rast\n",
            "Analizing oynak-nihavent\n",
            "\tBroken nihavent, oynak\n",
            "Analizing oynak-ussak\n",
            "\tBroken ussak, oynak\n",
            "Analizing oynak-segah\n",
            "\tAnalyzed oynak-segah\n",
            "Analizing oynak-huseyni\n",
            "\tBroken huseyni, oynak\n",
            "Analizing oynak-huzzam\n",
            "\tAnalyzed oynak-huzzam\n",
            "Analizing oynak-mahur\n",
            "\tBroken mahur, oynak\n",
            "Analizing oynak-kurdilihicazkar\n",
            "\tBroken kurdilihicazkar, oynak\n",
            "Analizing oynak-muhayyer\n",
            "\tBroken muhayyer, oynak\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}