{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GTPoY6FR79v1"
   },
   "source": [
    "# Check if is executing on Google Colab\n",
    "If running on google colab download the repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FPhBcNYs79v7",
    "outputId": "23c22d57-7df1-43e3-edf7-8e30cb6a1317"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  !git clone --recursive https://github.com/migperfer/AMPL-UPF-MSC\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AkjDrcqD79wT"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pigB1EWs79wZ"
   },
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "from music21.note import Note as noteclass\n",
    "from music21.chord import Chord as chordclass\n",
    "from music21.meter import TimeSignature as tsclass\n",
    "import os, glob, math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptf1XNm379wr"
   },
   "source": [
    "# Creation of Usul related objects\n",
    "## Definition of the UsulStroke and Usul classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3bTE_Kw79ww"
   },
   "outputs": [],
   "source": [
    "class UsulStroke:\n",
    "  def __init__(self, mnote, stroke, barduration):    \n",
    "    self.stroketype = stroke.content\n",
    "    self.duration = mnote.duration.quarterLength\n",
    "    self.offset = mnote.beat\n",
    "    self.barduration = barduration\n",
    "    self.compatoffset = float((mnote.beat - 1)/barduration)\n",
    "    if isinstance(mnote, chordclass):\n",
    "      self.hand = \"both\"\n",
    "    elif mnote.pitch.name == \"F\":\n",
    "      self.hand = \"right\"\n",
    "    elif mnote.pitch.name == \"D\":\n",
    "      self.hand = \"left\"\n",
    "    else:\n",
    "      self.hand = \"unknown\"\n",
    "\n",
    "  def __repr__(self):\n",
    "    return \"UsulStroke\"\n",
    "\n",
    "  def __str__(self):\n",
    "    return \"Stroke:%s, Duration:%s, Hand:%s, Offset:%s(%s)\" % (self.stroketype, self.duration, self.hand, self.compatoffset, type(self.compatoffset))\n",
    "\n",
    "class Usul:\n",
    "  def __init__(self, usulname, strokes, nbeats):\n",
    "    self.nbeats = nbeats\n",
    "    self.usul = usulname\n",
    "    self.strokes = strokes\n",
    "\n",
    "  @classmethod\n",
    "  def usul_from_file(cls, file):\n",
    "    nbeats = 0\n",
    "    score = converter.parse(file)\n",
    "    rhythm = score.getElementsByClass('Part')[0].getElementsByClass('Measure')[0]\n",
    "    notes = []\n",
    "    for element in rhythm:\n",
    "      if isinstance(element, (noteclass, chordclass)):\n",
    "        notes.append(element)\n",
    "      if isinstance(element, (tsclass)):\n",
    "        nbeats = element.beatCount\n",
    "        \n",
    "    strokes = rhythm.getElementsByClass('TextExpression')\n",
    "    usul_name = file.split('/')[-1].split('.mxl')[0].lower().replace('_', ' ')\n",
    "    strokes_list = []\n",
    "    for note in range(len(notes)):\n",
    "      strk = UsulStroke(notes[note], strokes[note], nbeats)\n",
    "      strokes_list.append(strk)\n",
    "    return cls(usul_name, strokes_list, nbeats)\n",
    "\n",
    "\n",
    "  def __iter__(self):\n",
    "    self.index = 0\n",
    "    return self\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "        return self.strokes[idx]\n",
    "\n",
    "  def __next__(self):\n",
    "    if self.index < len(self.strokes):\n",
    "      idx = self.index\n",
    "      self.index += 1\n",
    "      return self.strokes[idx]\n",
    "    else:\n",
    "      raise StopIteration\n",
    "\n",
    "  def _repr__(self):\n",
    "    return \"Usul\"\n",
    "  \n",
    "  def __str__(self):\n",
    "    return \"Usul Object: %s\" % (self.usul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-q72Ozi79w5"
   },
   "source": [
    "## Load all existing usuls with the classes created in last cell\n",
    "\n",
    "We load all the usuls possible (the ones for which we have the scores), into the *usul_dict* dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Z4yv3wA79w7"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    usuls_files_list = glob.glob('./AMPL-UPF-MSC/scores/mxl/*.mxl')\n",
    "else:\n",
    "    usuls_files_list = glob.glob('./scores/mxl/*.mxl')\n",
    "\n",
    "usuls_dict = {}\n",
    "for usul_file in usuls_files_list:\n",
    "  usul_name = usul_file.split('/')[-1].split('.mxl')[0].lower().replace('_', ' ')\n",
    "  if '\\\\' in usul_name:  # Windows use \\ instead of /\n",
    "        usul_name = usul_name.split('\\\\')[-1]\n",
    "  usuls_dict[usul_name] = Usul.usul_from_file(usul_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nPzngwqJ79xH"
   },
   "source": [
    "## Load all makams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B3sh0pIv79xJ"
   },
   "outputs": [],
   "source": [
    "usuldict = {'sofyan':0,'duyek':1,'raksaksagi':2,'cenber':3,'hafif':4,'devrikebir':5,'muhammes':6,'turkaksagi':7,'oynak':8,'havi':9,'aksak':10,'yuruksemai':11,'berefsan':12,'aksaksemai':13,'fahte':14,'semai':15,'cifteduyek':16,'evfer':17}\n",
    "makamlist = ['hicaz','rast','nihavent','ussak','segah','huseyni','huzzam','mahur','kurdilihicazkar','muhayyer']\n",
    "makamdict = {makamlist[i]:i for i in range(len(makamlist))}\n",
    "\n",
    "rast = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'D5','Lead':'F4#'}\n",
    "huseyni = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'E5','Lead':'G4'}\n",
    "muhayyer = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'A5','sDom':'E5','Lead':'G4'}\n",
    "ussak = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'D5','Lead':'G4'}\n",
    "hicaz = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'D5','Lead':'G4'}\n",
    "huzzam = {'B':1,'C':2,'D':3,'E':4,'F':5, 'G':6,'A':7,'Dom':'D5','Lead':'A4#'}\n",
    "kurdilihicazkar = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'G5','Lead':'F4'} \n",
    "nihavent = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'D5','Lead':'F4#'}\n",
    "segah = {'B':1,'C':2,'D':3,'E':4,'F':5, 'G':6,'A':7,'Dom':'D5','Lead':'A4#'}\n",
    "mahur = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'G5','Lead':'F4#'}\n",
    "\n",
    "if IN_COLAB:\n",
    "    folder = 'AMPL-UPF-MSC/SymbTr/txt/'\n",
    "else:\n",
    "    folder = 'SymbTr/txt/'\n",
    "\n",
    "allScores = os.listdir(folder)\n",
    "\n",
    "def getDegree(note,makam):\n",
    "    significance = None\n",
    "    degree = eval(makam)[note[0]]\n",
    "    if degree == 1:\n",
    "        significance = 'Tonic'\n",
    "    if note[:2] == eval(makam)['Dom']:\n",
    "        significance = 'Dominant'\n",
    "    if note[:2] == eval(makam)['Lead']:\n",
    "        significance = 'Leading'    \n",
    "    return degree,significance\n",
    "\n",
    "def getbars(makam,usul):\n",
    "    bars = []\n",
    "    bar = []\n",
    "    for file in allScores:\n",
    "        mak,_,us = file.split('--')[:3]\n",
    "        \n",
    "        if (mak != makam) or (us != usul):\n",
    "            continue\n",
    "        \n",
    "        with open(folder + file, encoding=\"utf8\") as scoretxt:\n",
    "            txtlines = scoretxt.read().split('\\n')\n",
    "        for i in range(2,len(txtlines)-1):\n",
    "            if int(txtlines[i].split('\\t')[1])==51: # possible usul change, leave the rest\n",
    "                break\n",
    "            if int(txtlines[i].split('\\t')[6])>0:\n",
    "                dur = int(txtlines[i].split('\\t')[6])/int(txtlines[i].split('\\t')[7])\n",
    "                notename = txtlines[i].split('\\t')[3]\n",
    "                degree, significance = getDegree(notename,mak)\n",
    "                offset = txtlines[i].split('\\t')[-1]     \n",
    "                bar.append([offset,dur,notename,degree,significance])\n",
    "                if float(offset).is_integer():\n",
    "                    bars.append(bar)\n",
    "                    bar = []\n",
    "    return bars\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9zYK8E379xS"
   },
   "source": [
    "## Function to analyze a makam using an usul object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4s6qrPZ79xW"
   },
   "outputs": [],
   "source": [
    "def analyze_makam(makam_name, usul_name):\n",
    "    usul_part = usuldict[usul_name.replace(\"ü\", \"u\").replace(\" \", \"\").replace(\"ç\",\"c\").replace(\"ğ\",\"g\").replace(\"ş\",\"s\").replace(\"-\",\"\")]\n",
    "    makam_part = makamdict[makam_name]\n",
    "    makam = getbars(makam_name, usul_name)\n",
    "    usul = usuls_dict[usul_name]\n",
    "    coincidences = []\n",
    "    usul_onsets = []\n",
    "    for stroke in usul:\n",
    "        usul_onsets.append(stroke.compatoffset)  # Get the position of every stroke in this\n",
    "    onsets_indx = dict((k,i) for i,k in enumerate(usul_onsets))  # Store the index of every beat position\n",
    "    for bar in makam:\n",
    "        for note in bar:\n",
    "            beat, bar = math.modf(float(note[0]))  # Split the integer part and the decimal one\n",
    "            beat = beat - note[1]  # Substract the duration, to get the beat position\n",
    "            if beat in usul_onsets:\n",
    "                coinc_stroke = usul[onsets_indx[beat]]  # Get coincident stroke\n",
    "                coincidence = {'hand': coinc_stroke.hand, 'duration': coinc_stroke.duration, 'stroke': coinc_stroke.stroketype,\n",
    "                               'note_name': note[2], 'note_degree': note[3], 'note_significance': note[4], 'makam': makam_name, 'usul': usul_name}\n",
    "                coincidences.append(coincidence)\n",
    "    coincidences = pd.DataFrame(coincidences)\n",
    "    return coincidences\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wgBdQMtwEQKT"
   },
   "source": [
    "## Analyze the scores\n",
    "Analyze the scores and save them into a folder called _csv-data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aFflfzmT_h5R",
    "outputId": "7b27717f-ded2-4540-be4e-9f2c1ccd3dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizing aksak-hicaz\n",
      "\tEmpty:  aksak hicaz\n",
      "Analizing aksak-rast\n",
      "\tEmpty:  aksak rast\n",
      "Analizing aksak-nihavent\n",
      "\tEmpty:  aksak nihavent\n",
      "Analizing aksak-ussak\n",
      "\tEmpty:  aksak ussak\n",
      "Analizing aksak-segah\n",
      "\tEmpty:  aksak segah\n",
      "Analizing aksak-huseyni\n",
      "\tEmpty:  aksak huseyni\n",
      "Analizing aksak-huzzam\n",
      "\tEmpty:  aksak huzzam\n",
      "Analizing aksak-mahur\n",
      "\tEmpty:  aksak mahur\n",
      "Analizing aksak-kurdilihicazkar\n",
      "\tEmpty:  aksak kurdilihicazkar\n",
      "Analizing aksak-muhayyer\n",
      "\tEmpty:  aksak muhayyer\n",
      "Analizing aksak semai-hicaz\n",
      "\tEmpty:  aksak semai hicaz\n",
      "Analizing aksak semai-rast\n",
      "\tEmpty:  aksak semai rast\n",
      "Analizing aksak semai-nihavent\n",
      "\tEmpty:  aksak semai nihavent\n",
      "Analizing aksak semai-ussak\n",
      "\tEmpty:  aksak semai ussak\n",
      "Analizing aksak semai-segah\n",
      "\tEmpty:  aksak semai segah\n",
      "Analizing aksak semai-huseyni\n",
      "\tEmpty:  aksak semai huseyni\n",
      "Analizing aksak semai-huzzam\n",
      "\tEmpty:  aksak semai huzzam\n",
      "Analizing aksak semai-mahur\n",
      "\tEmpty:  aksak semai mahur\n",
      "Analizing aksak semai-kurdilihicazkar\n",
      "\tEmpty:  aksak semai kurdilihicazkar\n",
      "Analizing aksak semai-muhayyer\n",
      "\tEmpty:  aksak semai muhayyer\n",
      "Analizing berefşan-hicaz\n",
      "\tEmpty:  berefşan hicaz\n",
      "Analizing berefşan-rast\n",
      "\tEmpty:  berefşan rast\n",
      "Analizing berefşan-nihavent\n",
      "\tEmpty:  berefşan nihavent\n",
      "Analizing berefşan-ussak\n",
      "\tEmpty:  berefşan ussak\n",
      "Analizing berefşan-segah\n",
      "\tEmpty:  berefşan segah\n",
      "Analizing berefşan-huseyni\n",
      "\tEmpty:  berefşan huseyni\n",
      "Analizing berefşan-huzzam\n",
      "\tEmpty:  berefşan huzzam\n",
      "Analizing berefşan-mahur\n",
      "\tEmpty:  berefşan mahur\n",
      "Analizing berefşan-kurdilihicazkar\n",
      "\tEmpty:  berefşan kurdilihicazkar\n",
      "Analizing berefşan-muhayyer\n",
      "\tEmpty:  berefşan muhayyer\n",
      "Analizing devr-i kebir-hicaz\n",
      "\tEmpty:  devr-i kebir hicaz\n",
      "Analizing devr-i kebir-rast\n",
      "\tEmpty:  devr-i kebir rast\n",
      "Analizing devr-i kebir-nihavent\n",
      "\tEmpty:  devr-i kebir nihavent\n",
      "Analizing devr-i kebir-ussak\n",
      "\tEmpty:  devr-i kebir ussak\n",
      "Analizing devr-i kebir-segah\n",
      "\tEmpty:  devr-i kebir segah\n",
      "Analizing devr-i kebir-huseyni\n",
      "\tEmpty:  devr-i kebir huseyni\n",
      "Analizing devr-i kebir-huzzam\n",
      "\tEmpty:  devr-i kebir huzzam\n",
      "Analizing devr-i kebir-mahur\n",
      "\tEmpty:  devr-i kebir mahur\n",
      "Analizing devr-i kebir-kurdilihicazkar\n",
      "\tEmpty:  devr-i kebir kurdilihicazkar\n",
      "Analizing devr-i kebir-muhayyer\n",
      "\tEmpty:  devr-i kebir muhayyer\n",
      "Analizing düyek-hicaz\n",
      "\tEmpty:  düyek hicaz\n",
      "Analizing düyek-rast\n",
      "\tEmpty:  düyek rast\n",
      "Analizing düyek-nihavent\n",
      "\tEmpty:  düyek nihavent\n",
      "Analizing düyek-ussak\n",
      "\tEmpty:  düyek ussak\n",
      "Analizing düyek-segah\n",
      "\tEmpty:  düyek segah\n",
      "Analizing düyek-huseyni\n",
      "\tEmpty:  düyek huseyni\n",
      "Analizing düyek-huzzam\n",
      "\tEmpty:  düyek huzzam\n",
      "Analizing düyek-mahur\n",
      "\tEmpty:  düyek mahur\n",
      "Analizing düyek-kurdilihicazkar\n",
      "\tEmpty:  düyek kurdilihicazkar\n",
      "Analizing düyek-muhayyer\n",
      "\tEmpty:  düyek muhayyer\n",
      "Analizing evfer-hicaz\n",
      "\tEmpty:  evfer hicaz\n",
      "Analizing evfer-rast\n",
      "\tEmpty:  evfer rast\n",
      "Analizing evfer-nihavent\n",
      "\tEmpty:  evfer nihavent\n",
      "Analizing evfer-ussak\n",
      "\tEmpty:  evfer ussak\n",
      "Analizing evfer-segah\n",
      "\tEmpty:  evfer segah\n",
      "Analizing evfer-huseyni\n",
      "\tEmpty:  evfer huseyni\n",
      "Analizing evfer-huzzam\n",
      "\tEmpty:  evfer huzzam\n",
      "Analizing evfer-mahur\n",
      "\tEmpty:  evfer mahur\n",
      "Analizing evfer-kurdilihicazkar\n",
      "\tEmpty:  evfer kurdilihicazkar\n",
      "Analizing evfer-muhayyer\n",
      "\tEmpty:  evfer muhayyer\n",
      "Analizing fahte-hicaz\n",
      "\tAnalyzed fahte-hicaz\n",
      "Analizing fahte-rast\n",
      "\tEmpty:  fahte rast\n",
      "Analizing fahte-nihavent\n",
      "\tAnalyzed fahte-nihavent\n",
      "Analizing fahte-ussak\n",
      "\tEmpty:  fahte ussak\n",
      "Analizing fahte-segah\n",
      "\tEmpty:  fahte segah\n",
      "Analizing fahte-huseyni\n",
      "\tEmpty:  fahte huseyni\n",
      "Analizing fahte-huzzam\n",
      "\tAnalyzed fahte-huzzam\n",
      "Analizing fahte-mahur\n",
      "\tEmpty:  fahte mahur\n",
      "Analizing fahte-kurdilihicazkar\n",
      "\tEmpty:  fahte kurdilihicazkar\n",
      "Analizing fahte-muhayyer\n",
      "\tEmpty:  fahte muhayyer\n",
      "Analizing hafif-hicaz\n",
      "\tEmpty:  hafif hicaz\n",
      "Analizing hafif-rast\n",
      "\tAnalyzed hafif-rast\n",
      "Analizing hafif-nihavent\n",
      "\tAnalyzed hafif-nihavent\n",
      "Analizing hafif-ussak\n",
      "\tAnalyzed hafif-ussak\n",
      "Analizing hafif-segah\n",
      "\tAnalyzed hafif-segah\n",
      "Analizing hafif-huseyni\n",
      "\tEmpty:  hafif huseyni\n",
      "Analizing hafif-huzzam\n",
      "\tEmpty:  hafif huzzam\n",
      "Analizing hafif-mahur\n",
      "\tAnalyzed hafif-mahur\n",
      "Analizing hafif-kurdilihicazkar\n",
      "\tEmpty:  hafif kurdilihicazkar\n",
      "Analizing hafif-muhayyer\n",
      "\tEmpty:  hafif muhayyer\n",
      "Analizing havi-hicaz\n",
      "\tEmpty:  havi hicaz\n",
      "Analizing havi-rast\n",
      "\tEmpty:  havi rast\n",
      "Analizing havi-nihavent\n",
      "\tEmpty:  havi nihavent\n",
      "Analizing havi-ussak\n",
      "\tEmpty:  havi ussak\n",
      "Analizing havi-segah\n",
      "\tEmpty:  havi segah\n",
      "Analizing havi-huseyni\n",
      "\tAnalyzed havi-huseyni\n",
      "Analizing havi-huzzam\n",
      "\tEmpty:  havi huzzam\n",
      "Analizing havi-mahur\n",
      "\tEmpty:  havi mahur\n",
      "Analizing havi-kurdilihicazkar\n",
      "\tEmpty:  havi kurdilihicazkar\n",
      "Analizing havi-muhayyer\n",
      "\tEmpty:  havi muhayyer\n",
      "Analizing muhammes-hicaz\n",
      "\tEmpty:  muhammes hicaz\n",
      "Analizing muhammes-rast\n",
      "\tAnalyzed muhammes-rast\n",
      "Analizing muhammes-nihavent\n",
      "\tEmpty:  muhammes nihavent\n",
      "Analizing muhammes-ussak\n",
      "\tEmpty:  muhammes ussak\n",
      "Analizing muhammes-segah\n",
      "\tEmpty:  muhammes segah\n",
      "Analizing muhammes-huseyni\n",
      "\tAnalyzed muhammes-huseyni\n",
      "Analizing muhammes-huzzam\n",
      "\tAnalyzed muhammes-huzzam\n",
      "Analizing muhammes-mahur\n",
      "\tAnalyzed muhammes-mahur\n",
      "Analizing muhammes-kurdilihicazkar\n",
      "\tAnalyzed muhammes-kurdilihicazkar\n",
      "Analizing muhammes-muhayyer\n",
      "\tAnalyzed muhammes-muhayyer\n",
      "Analizing oynak-hicaz\n",
      "\tEmpty:  oynak hicaz\n",
      "Analizing oynak-rast\n",
      "\tEmpty:  oynak rast\n",
      "Analizing oynak-nihavent\n",
      "\tEmpty:  oynak nihavent\n",
      "Analizing oynak-ussak\n",
      "\tEmpty:  oynak ussak\n",
      "Analizing oynak-segah\n",
      "\tEmpty:  oynak segah\n",
      "Analizing oynak-huseyni\n",
      "\tEmpty:  oynak huseyni\n",
      "Analizing oynak-huzzam\n",
      "\tEmpty:  oynak huzzam\n",
      "Analizing oynak-mahur\n",
      "\tEmpty:  oynak mahur\n",
      "Analizing oynak-kurdilihicazkar\n",
      "\tEmpty:  oynak kurdilihicazkar\n",
      "Analizing oynak-muhayyer\n",
      "\tEmpty:  oynak muhayyer\n",
      "Analizing raks aksaği-hicaz\n",
      "\tEmpty:  raks aksaği hicaz\n",
      "Analizing raks aksaği-rast\n",
      "\tEmpty:  raks aksaği rast\n",
      "Analizing raks aksaği-nihavent\n",
      "\tEmpty:  raks aksaği nihavent\n",
      "Analizing raks aksaği-ussak\n",
      "\tEmpty:  raks aksaği ussak\n",
      "Analizing raks aksaği-segah\n",
      "\tEmpty:  raks aksaği segah\n",
      "Analizing raks aksaği-huseyni\n",
      "\tEmpty:  raks aksaği huseyni\n",
      "Analizing raks aksaği-huzzam\n",
      "\tEmpty:  raks aksaği huzzam\n",
      "Analizing raks aksaği-mahur\n",
      "\tEmpty:  raks aksaği mahur\n",
      "Analizing raks aksaği-kurdilihicazkar\n",
      "\tEmpty:  raks aksaği kurdilihicazkar\n",
      "Analizing raks aksaği-muhayyer\n",
      "\tEmpty:  raks aksaği muhayyer\n",
      "Analizing semai-hicaz\n",
      "\tEmpty:  semai hicaz\n",
      "Analizing semai-rast\n",
      "\tEmpty:  semai rast\n",
      "Analizing semai-nihavent\n",
      "\tEmpty:  semai nihavent\n",
      "Analizing semai-ussak\n",
      "\tEmpty:  semai ussak\n",
      "Analizing semai-segah\n",
      "\tEmpty:  semai segah\n",
      "Analizing semai-huseyni\n",
      "\tEmpty:  semai huseyni\n",
      "Analizing semai-huzzam\n",
      "\tEmpty:  semai huzzam\n",
      "Analizing semai-mahur\n",
      "\tEmpty:  semai mahur\n",
      "Analizing semai-kurdilihicazkar\n",
      "\tEmpty:  semai kurdilihicazkar\n",
      "Analizing semai-muhayyer\n",
      "\tEmpty:  semai muhayyer\n",
      "Analizing sofyan-hicaz\n",
      "\tAnalyzed sofyan-hicaz\n",
      "Analizing sofyan-rast\n",
      "\tAnalyzed sofyan-rast\n",
      "Analizing sofyan-nihavent\n",
      "\tAnalyzed sofyan-nihavent\n",
      "Analizing sofyan-ussak\n",
      "\tAnalyzed sofyan-ussak\n",
      "Analizing sofyan-segah\n",
      "\tAnalyzed sofyan-segah\n",
      "Analizing sofyan-huseyni\n",
      "\tAnalyzed sofyan-huseyni\n",
      "Analizing sofyan-huzzam\n",
      "\tAnalyzed sofyan-huzzam\n",
      "Analizing sofyan-mahur\n",
      "\tAnalyzed sofyan-mahur\n",
      "Analizing sofyan-kurdilihicazkar\n",
      "\tAnalyzed sofyan-kurdilihicazkar\n",
      "Analizing sofyan-muhayyer\n",
      "\tAnalyzed sofyan-muhayyer\n",
      "Analizing türk aksaği-hicaz\n",
      "\tEmpty:  türk aksaği hicaz\n",
      "Analizing türk aksaği-rast\n",
      "\tEmpty:  türk aksaği rast\n",
      "Analizing türk aksaği-nihavent\n",
      "\tEmpty:  türk aksaği nihavent\n",
      "Analizing türk aksaği-ussak\n",
      "\tEmpty:  türk aksaği ussak\n",
      "Analizing türk aksaği-segah\n",
      "\tEmpty:  türk aksaği segah\n",
      "Analizing türk aksaği-huseyni\n",
      "\tEmpty:  türk aksaği huseyni\n",
      "Analizing türk aksaği-huzzam\n",
      "\tEmpty:  türk aksaği huzzam\n",
      "Analizing türk aksaği-mahur\n",
      "\tEmpty:  türk aksaği mahur\n",
      "Analizing türk aksaği-kurdilihicazkar\n",
      "\tEmpty:  türk aksaği kurdilihicazkar\n",
      "Analizing türk aksaği-muhayyer\n",
      "\tEmpty:  türk aksaği muhayyer\n",
      "Analizing yürük semai-hicaz\n",
      "\tEmpty:  yürük semai hicaz\n",
      "Analizing yürük semai-rast\n",
      "\tEmpty:  yürük semai rast\n",
      "Analizing yürük semai-nihavent\n",
      "\tEmpty:  yürük semai nihavent\n",
      "Analizing yürük semai-ussak\n",
      "\tEmpty:  yürük semai ussak\n",
      "Analizing yürük semai-segah\n",
      "\tEmpty:  yürük semai segah\n",
      "Analizing yürük semai-huseyni\n",
      "\tEmpty:  yürük semai huseyni\n",
      "Analizing yürük semai-huzzam\n",
      "\tEmpty:  yürük semai huzzam\n",
      "Analizing yürük semai-mahur\n",
      "\tEmpty:  yürük semai mahur\n",
      "Analizing yürük semai-kurdilihicazkar\n",
      "\tEmpty:  yürük semai kurdilihicazkar\n",
      "Analizing yürük semai-muhayyer\n",
      "\tEmpty:  yürük semai muhayyer\n",
      "Analizing çenber-hicaz\n",
      "\tEmpty:  çenber hicaz\n",
      "Analizing çenber-rast\n",
      "\tEmpty:  çenber rast\n",
      "Analizing çenber-nihavent\n",
      "\tEmpty:  çenber nihavent\n",
      "Analizing çenber-ussak\n",
      "\tEmpty:  çenber ussak\n",
      "Analizing çenber-segah\n",
      "\tEmpty:  çenber segah\n",
      "Analizing çenber-huseyni\n",
      "\tEmpty:  çenber huseyni\n",
      "Analizing çenber-huzzam\n",
      "\tEmpty:  çenber huzzam\n",
      "Analizing çenber-mahur\n",
      "\tEmpty:  çenber mahur\n",
      "Analizing çenber-kurdilihicazkar\n",
      "\tEmpty:  çenber kurdilihicazkar\n",
      "Analizing çenber-muhayyer\n",
      "\tEmpty:  çenber muhayyer\n",
      "Analizing çifte düyek-hicaz\n",
      "\tEmpty:  çifte düyek hicaz\n",
      "Analizing çifte düyek-rast\n",
      "\tEmpty:  çifte düyek rast\n",
      "Analizing çifte düyek-nihavent\n",
      "\tEmpty:  çifte düyek nihavent\n",
      "Analizing çifte düyek-ussak\n",
      "\tEmpty:  çifte düyek ussak\n",
      "Analizing çifte düyek-segah\n",
      "\tEmpty:  çifte düyek segah\n",
      "Analizing çifte düyek-huseyni\n",
      "\tEmpty:  çifte düyek huseyni\n",
      "Analizing çifte düyek-huzzam\n",
      "\tEmpty:  çifte düyek huzzam\n",
      "Analizing çifte düyek-mahur\n",
      "\tEmpty:  çifte düyek mahur\n",
      "Analizing çifte düyek-kurdilihicazkar\n",
      "\tEmpty:  çifte düyek kurdilihicazkar\n",
      "Analizing çifte düyek-muhayyer\n",
      "\tEmpty:  çifte düyek muhayyer\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('csv-data/'):\n",
    "  os.mkdir('csv-data/')\n",
    "import gc\n",
    "empty_ones = []\n",
    "for usul_key in usuls_dict.keys():\n",
    "  for makam_key in makamdict.keys():\n",
    "    print(\"Analizing %s-%s\" % (usul_key, makam_key))\n",
    "    results = analyze_makam(makam_key, usul_key)\n",
    "    if not results.empty:\n",
    "      results.to_csv('csv-data/%s-%s.csv' % (usul_key, makam_key))\n",
    "      print(\"\\tAnalyzed %s-%s\" % (usul_key, makam_key))\n",
    "    else:\n",
    "      print(\"\\tEmpty: \", usul_key, makam_key)\n",
    "      empty_ones.append(\"%s-%s\" % (usul_key, makam_key))\n",
    "  gc.collect()\n",
    "with open('csv-data/empty_ones.txt', 'w', encoding=\"utf8\") as file:\n",
    "  for empty in empty_ones:\n",
    "    file.write(\"%s\\n\" %empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Check usuls_makams.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
