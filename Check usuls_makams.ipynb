{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Check usuls_makams.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTPoY6FR79v1",
        "colab_type": "text"
      },
      "source": [
        "# Check if is executing on Google Colab\n",
        "If running on google colab download the repositories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPhBcNYs79v7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "23c22d57-7df1-43e3-edf7-8e30cb6a1317"
      },
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  !git clone --recursive https://github.com/migperfer/AMPL-UPF-MSC\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'AMPL-UPF-MSC' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkjDrcqD79wT",
        "colab_type": "text"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pigB1EWs79wZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from music21 import *\n",
        "from music21.note import Note as noteclass\n",
        "from music21.chord import Chord as chordclass\n",
        "from music21.meter import TimeSignature as tsclass\n",
        "import os, glob, math\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptf1XNm379wr",
        "colab_type": "text"
      },
      "source": [
        "# Creation of Usul related objects\n",
        "## Definition of the UsulStroke and Usul classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3bTE_Kw79ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UsulStroke:\n",
        "  def __init__(self, mnote, stroke, barduration):    \n",
        "    self.stroketype = stroke.content\n",
        "    self.duration = mnote.duration.quarterLength\n",
        "    self.offset = mnote.beat\n",
        "    self.barduration = barduration\n",
        "    self.compatoffset = float((mnote.beat - 1)/barduration)\n",
        "    if isinstance(mnote, chordclass):\n",
        "      self.hand = \"both\"\n",
        "    elif mnote.pitch.name == \"F\":\n",
        "      self.hand = \"right\"\n",
        "    elif mnote.pitch.name == \"D\":\n",
        "      self.hand = \"left\"\n",
        "    else:\n",
        "      self.hand = \"unknown\"\n",
        "\n",
        "  def __repr__(self):\n",
        "    return \"UsulStroke\"\n",
        "\n",
        "  def __str__(self):\n",
        "    return \"Stroke:%s, Duration:%s, Hand:%s, Offset:%s(%s)\" % (self.stroketype, self.duration, self.hand, self.compatoffset, type(self.compatoffset))\n",
        "\n",
        "class Usul:\n",
        "  def __init__(self, usulname, strokes, nbeats):\n",
        "    self.nbeats = nbeats\n",
        "    self.usul = usulname\n",
        "    self.strokes = strokes\n",
        "\n",
        "  @classmethod\n",
        "  def usul_from_file(cls, file):\n",
        "    nbeats = 0\n",
        "    score = converter.parse(file)\n",
        "    rhythm = score.getElementsByClass('Part')[0].getElementsByClass('Measure')[0]\n",
        "    notes = []\n",
        "    for element in rhythm:\n",
        "      if isinstance(element, (noteclass, chordclass)):\n",
        "        notes.append(element)\n",
        "      if isinstance(element, (tsclass)):\n",
        "        nbeats = element.beatCount\n",
        "        \n",
        "    strokes = rhythm.getElementsByClass('TextExpression')\n",
        "    usul_name = file.split('/')[-1].split('.mxl')[0].lower().replace('_', ' ')\n",
        "    strokes_list = []\n",
        "    for note in range(len(notes)):\n",
        "      strk = UsulStroke(notes[note], strokes[note], nbeats)\n",
        "      strokes_list.append(strk)\n",
        "    return cls(usul_name, strokes_list, nbeats)\n",
        "\n",
        "\n",
        "  def __iter__(self):\n",
        "    self.index = 0\n",
        "    return self\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "        return self.strokes[idx]\n",
        "\n",
        "  def __next__(self):\n",
        "    if self.index < len(self.strokes):\n",
        "      idx = self.index\n",
        "      self.index += 1\n",
        "      return self.strokes[idx]\n",
        "    else:\n",
        "      raise StopIteration\n",
        "\n",
        "  def _repr__(self):\n",
        "    return \"Usul\"\n",
        "  \n",
        "  def __str__(self):\n",
        "    return \"Usul Object: %s\" % (self.usul)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-q72Ozi79w5",
        "colab_type": "text"
      },
      "source": [
        "## Load all existing usuls with the classes created in last cell\n",
        "\n",
        "We load all the usuls possible (the ones for which we have the scores), into the *usul_dict* dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z4yv3wA79w7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if IN_COLAB:\n",
        "    usuls_files_list = glob.glob('./AMPL-UPF-MSC/scores/mxl/*.mxl')\n",
        "else:\n",
        "    usuls_files_list = glob.glob('./scores/mxl/*.mxl')\n",
        "\n",
        "usuls_dict = {}\n",
        "for usul_file in usuls_files_list:\n",
        "  usul_name = usul_file.split('/')[-1].split('.mxl')[0].lower().replace('_', ' ')\n",
        "  if '\\\\' in usul_name:  # Windows use \\ instead of /\n",
        "        usul_name = usul_name.split('\\\\')[-1]\n",
        "  usuls_dict[usul_name] = Usul.usul_from_file(usul_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPzngwqJ79xH",
        "colab_type": "text"
      },
      "source": [
        "## Load all makams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3sh0pIv79xJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "usuldict = {'sofyan':0,'duyek':1,'raksaksagi':2,'cenber':3,'hafif':4,'devrikebir':5,'muhammes':6,'turkaksagi':7,'oynak':8,'havi':9,'aksak':10,'yuruksemai':11,'berefsan':12,'aksaksemai':13,'fahte':14,'semai':15,'cifteduyek':16,'evfer':17}\n",
        "makamlist = ['hicaz','rast','nihavent','ussak','segah','huseyni','huzzam','mahur','kurdilihicazkar','muhayyer']\n",
        "makamdict = {makamlist[i]:i for i in range(len(makamlist))}\n",
        "\n",
        "rast = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'D5','Lead':'F4#'}\n",
        "huseyni = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'E5','Lead':'G4'}\n",
        "muhayyer = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'A5','sDom':'E5','Lead':'G4'}\n",
        "ussak = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'D5','Lead':'G4'}\n",
        "hicaz = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'D5','Lead':'G4'}\n",
        "huzzam = {'B':1,'C':2,'D':3,'E':4,'F':5, 'G':6,'A':7,'Dom':'D5','Lead':'A4#'}\n",
        "kurdilihicazkar = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'G5','Lead':'F4'} \n",
        "nihavent = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'D5','Lead':'F4#'}\n",
        "segah = {'B':1,'C':2,'D':3,'E':4,'F':5, 'G':6,'A':7,'Dom':'D5','Lead':'A4#'}\n",
        "mahur = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'G5','Lead':'F4#'}\n",
        "\n",
        "if IN_COLAB:\n",
        "    folder = 'AMPL-UPF-MSC/SymbTr/txt/'\n",
        "else:\n",
        "    folder = 'SymbTr/txt/'\n",
        "\n",
        "allScores = os.listdir(folder)\n",
        "\n",
        "def getDegree(note,makam):\n",
        "    significance = None\n",
        "    degree = eval(makam)[note[0]]\n",
        "    if degree == 1:\n",
        "        significance = 'Tonic'\n",
        "    if note[:2] == eval(makam)['Dom']:\n",
        "        significance = 'Dominant'\n",
        "    if note[:2] == eval(makam)['Lead']:\n",
        "        significance = 'Leading'    \n",
        "    return degree,significance\n",
        "\n",
        "scorelist = [[]]\n",
        "for u in range(len(usuldict)):\n",
        "    scorelist.append([])\n",
        "    for m in range(len(makamdict)):\n",
        "        scorelist[u].append([])\n",
        "        \n",
        "for file in allScores:\n",
        "    mak,_,us = file.split('--')[:3]\n",
        "    if mak not in makamdict or us not in usuldict:\n",
        "        continue\n",
        "    with open(folder + file, encoding=\"utf8\") as scoretxt:\n",
        "        try:\n",
        "            txtlines = scoretxt.read().split('\\n')\n",
        "        except UnicodeDecodeError as e:\n",
        "            print(\"Error in file: %s\" % file)\n",
        "            print(str(e))\n",
        "    for i in range(2,len(txtlines)-1):\n",
        "        if int(txtlines[i].split('\\t')[1])==51: # possible usul change, leave the rest\n",
        "            break\n",
        "        if int(txtlines[i].split('\\t')[6])>0:\n",
        "            dur = int(txtlines[i].split('\\t')[6])/int(txtlines[i].split('\\t')[7])\n",
        "            name = txtlines[i].split('\\t')[3]\n",
        "            degree, significance = getDegree(name,mak)\n",
        "            offset = txtlines[i].split('\\t')[-1]     \n",
        "            scorelist[usuldict[us]][makamdict[mak]].append([offset,dur,name,degree,significance])\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9zYK8E379xS",
        "colab_type": "text"
      },
      "source": [
        "## Function to analyze a makam using an usul object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4s6qrPZ79xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze_makam(scorelist, usuldict, makamdict, makam_name, usul_name):\n",
        "    usul_part = usuldict[usul_name.replace(\"ü\", \"u\").replace(\" \", \"\").replace(\"ç\",\"c\").replace(\"ğ\",\"g\").replace(\"ş\",\"s\")]\n",
        "    makam_part = makamdict[makam_name]\n",
        "    makam = scorelist[usul_part][makam_part]\n",
        "    usul = usuls_dict[usul_name]\n",
        "    coincidences = []\n",
        "    usul_onsets = []\n",
        "    for stroke in usul:\n",
        "        usul_onsets.append(stroke.compatoffset)  # Get the position of every stroke in this\n",
        "    onsets_indx = dict((k,i) for i,k in enumerate(usul_onsets))  # Store the index of every beat position\n",
        "    for bar in makam:\n",
        "        for note in makam:\n",
        "            beat, bar = math.modf(float(note[0]))  # Split the integer part and the decimal one\n",
        "            beat = beat - note[1]  # Substract the duration, to get the beat position\n",
        "            if beat in usul_onsets:\n",
        "                coinc_stroke = usul[onsets_indx[beat]]  # Get coincident stroke\n",
        "                coincidence = {'hand': coinc_stroke.hand, 'duration': coinc_stroke.duration, 'stroke': coinc_stroke.stroketype,\n",
        "                               'note_name': note[2], 'note_degree': note[3], 'note_significance': note[4], 'makam': makam_name, 'usul': usul_name}\n",
        "                coincidences.append(coincidence)\n",
        "    coincidences = pd.DataFrame(coincidences)\n",
        "    return coincidences\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgBdQMtwEQKT",
        "colab_type": "text"
      },
      "source": [
        "## Analyze the scores\n",
        "Analyze the scores and save them into a folder called _csv-data_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFflfzmT_h5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b27717f-ded2-4540-be4e-9f2c1ccd3dff"
      },
      "source": [
        "if not os.path.isdir('csv-data/'):\n",
        "  os.mkdir('csv-data/')\n",
        "import gc\n",
        "empty_ones = []\n",
        "for usul_key in usuls_dict.keys():\n",
        "  for makam_key in makamdict.keys():\n",
        "    print(\"Analizing %s-%s\" % (usul_key, makam_key))\n",
        "    results = analyze_makam(scorelist, usuldict, makamdict, makam_key, usul_key)\n",
        "    if not results.empty:\n",
        "      results.to_csv('csv-data/%s-%s.csv' % (usul_key, makam_key))\n",
        "      print(\"\\tAnalyzed %s-%s\" % (usul_key, makam_key))\n",
        "    else:\n",
        "      print(\"\\tEmpty: \", usul_key, makam_key)\n",
        "      empty_ones.append(\"%s-%s\" % (usul_key, makam_key))\n",
        "  gc.collect()\n",
        "with open('csv-data/empty_ones.txt', 'w') as file:\n",
        "  for empty in empty_ones:\n",
        "    file.write(\"%s\\n\" %empty)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analizing evfer-hicaz\n",
            "\tEmpty:  evfer hicaz\n",
            "Analizing evfer-rast\n",
            "\tEmpty:  evfer rast\n",
            "Analizing evfer-nihavent\n",
            "\tEmpty:  evfer nihavent\n",
            "Analizing evfer-ussak\n",
            "\tEmpty:  evfer ussak\n",
            "Analizing evfer-segah\n",
            "\tEmpty:  evfer segah\n",
            "Analizing evfer-huseyni\n",
            "\tEmpty:  evfer huseyni\n",
            "Analizing evfer-huzzam\n",
            "\tEmpty:  evfer huzzam\n",
            "Analizing evfer-mahur\n",
            "\tEmpty:  evfer mahur\n",
            "Analizing evfer-kurdilihicazkar\n",
            "\tEmpty:  evfer kurdilihicazkar\n",
            "Analizing evfer-muhayyer\n",
            "\tEmpty:  evfer muhayyer\n",
            "Analizing çenber-hicaz\n",
            "\tEmpty:  çenber hicaz\n",
            "Analizing çenber-rast\n",
            "\tAnalyzed çenber-rast\n",
            "Analizing çenber-nihavent\n",
            "\tEmpty:  çenber nihavent\n",
            "Analizing çenber-ussak\n",
            "\tAnalyzed çenber-ussak\n",
            "Analizing çenber-segah\n",
            "\tEmpty:  çenber segah\n",
            "Analizing çenber-huseyni\n",
            "\tAnalyzed çenber-huseyni\n",
            "Analizing çenber-huzzam\n",
            "\tEmpty:  çenber huzzam\n",
            "Analizing çenber-mahur\n",
            "\tEmpty:  çenber mahur\n",
            "Analizing çenber-kurdilihicazkar\n",
            "\tEmpty:  çenber kurdilihicazkar\n",
            "Analizing çenber-muhayyer\n",
            "\tEmpty:  çenber muhayyer\n",
            "Analizing fahte-hicaz\n",
            "\tAnalyzed fahte-hicaz\n",
            "Analizing fahte-rast\n",
            "\tEmpty:  fahte rast\n",
            "Analizing fahte-nihavent\n",
            "\tAnalyzed fahte-nihavent\n",
            "Analizing fahte-ussak\n",
            "\tEmpty:  fahte ussak\n",
            "Analizing fahte-segah\n",
            "\tEmpty:  fahte segah\n",
            "Analizing fahte-huseyni\n",
            "\tEmpty:  fahte huseyni\n",
            "Analizing fahte-huzzam\n",
            "\tAnalyzed fahte-huzzam\n",
            "Analizing fahte-mahur\n",
            "\tEmpty:  fahte mahur\n",
            "Analizing fahte-kurdilihicazkar\n",
            "\tEmpty:  fahte kurdilihicazkar\n",
            "Analizing fahte-muhayyer\n",
            "\tEmpty:  fahte muhayyer\n",
            "Analizing oynak-hicaz\n",
            "\tEmpty:  oynak hicaz\n",
            "Analizing oynak-rast\n",
            "\tEmpty:  oynak rast\n",
            "Analizing oynak-nihavent\n",
            "\tEmpty:  oynak nihavent\n",
            "Analizing oynak-ussak\n",
            "\tEmpty:  oynak ussak\n",
            "Analizing oynak-segah\n",
            "\tEmpty:  oynak segah\n",
            "Analizing oynak-huseyni\n",
            "\tEmpty:  oynak huseyni\n",
            "Analizing oynak-huzzam\n",
            "\tEmpty:  oynak huzzam\n",
            "Analizing oynak-mahur\n",
            "\tEmpty:  oynak mahur\n",
            "Analizing oynak-kurdilihicazkar\n",
            "\tEmpty:  oynak kurdilihicazkar\n",
            "Analizing oynak-muhayyer\n",
            "\tEmpty:  oynak muhayyer\n",
            "Analizing çifte düyek-hicaz\n",
            "\tEmpty:  çifte düyek hicaz\n",
            "Analizing çifte düyek-rast\n",
            "\tAnalyzed çifte düyek-rast\n",
            "Analizing çifte düyek-nihavent\n",
            "\tEmpty:  çifte düyek nihavent\n",
            "Analizing çifte düyek-ussak\n",
            "\tEmpty:  çifte düyek ussak\n",
            "Analizing çifte düyek-segah\n",
            "\tEmpty:  çifte düyek segah\n",
            "Analizing çifte düyek-huseyni\n",
            "\tAnalyzed çifte düyek-huseyni\n",
            "Analizing çifte düyek-huzzam\n",
            "\tEmpty:  çifte düyek huzzam\n",
            "Analizing çifte düyek-mahur\n",
            "\tEmpty:  çifte düyek mahur\n",
            "Analizing çifte düyek-kurdilihicazkar\n",
            "\tEmpty:  çifte düyek kurdilihicazkar\n",
            "Analizing çifte düyek-muhayyer\n",
            "\tEmpty:  çifte düyek muhayyer\n",
            "Analizing türk aksaği-hicaz\n",
            "\tEmpty:  türk aksaği hicaz\n",
            "Analizing türk aksaği-rast\n",
            "\tEmpty:  türk aksaği rast\n",
            "Analizing türk aksaği-nihavent\n",
            "\tEmpty:  türk aksaği nihavent\n",
            "Analizing türk aksaği-ussak\n",
            "\tEmpty:  türk aksaği ussak\n",
            "Analizing türk aksaği-segah\n",
            "\tEmpty:  türk aksaği segah\n",
            "Analizing türk aksaği-huseyni\n",
            "\tEmpty:  türk aksaği huseyni\n",
            "Analizing türk aksaği-huzzam\n",
            "\tEmpty:  türk aksaği huzzam\n",
            "Analizing türk aksaği-mahur\n",
            "\tEmpty:  türk aksaği mahur\n",
            "Analizing türk aksaği-kurdilihicazkar\n",
            "\tEmpty:  türk aksaği kurdilihicazkar\n",
            "Analizing türk aksaği-muhayyer\n",
            "\tEmpty:  türk aksaği muhayyer\n",
            "Analizing berefşan-hicaz\n",
            "\tEmpty:  berefşan hicaz\n",
            "Analizing berefşan-rast\n",
            "\tEmpty:  berefşan rast\n",
            "Analizing berefşan-nihavent\n",
            "\tEmpty:  berefşan nihavent\n",
            "Analizing berefşan-ussak\n",
            "\tEmpty:  berefşan ussak\n",
            "Analizing berefşan-segah\n",
            "\tEmpty:  berefşan segah\n",
            "Analizing berefşan-huseyni\n",
            "\tAnalyzed berefşan-huseyni\n",
            "Analizing berefşan-huzzam\n",
            "\tEmpty:  berefşan huzzam\n",
            "Analizing berefşan-mahur\n",
            "\tEmpty:  berefşan mahur\n",
            "Analizing berefşan-kurdilihicazkar\n",
            "\tEmpty:  berefşan kurdilihicazkar\n",
            "Analizing berefşan-muhayyer\n",
            "\tEmpty:  berefşan muhayyer\n",
            "Analizing düyek-hicaz\n",
            "\tAnalyzed düyek-hicaz\n",
            "Analizing düyek-rast\n",
            "\tAnalyzed düyek-rast\n",
            "Analizing düyek-nihavent\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}