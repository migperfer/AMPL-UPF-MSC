{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Check usuls_makams.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/migperfer/AMPL-UPF-MSC/blob/master/Check%20usuls_makams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GTPoY6FR79v1"
      },
      "source": [
        "# Check if is executing on Google Colab\n",
        "If running on google colab download the repositories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FPhBcNYs79v7",
        "outputId": "368c1499-9007-4ec8-c0c4-ff6758bbd086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  !git clone --recursive https://github.com/migperfer/AMPL-UPF-MSC\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'AMPL-UPF-MSC' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AkjDrcqD79wT"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pigB1EWs79wZ",
        "colab": {}
      },
      "source": [
        "from music21 import *\n",
        "from music21.note import Note as noteclass\n",
        "from music21.chord import Chord as chordclass\n",
        "from music21.meter import TimeSignature as tsclass\n",
        "import os, glob, math\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ptf1XNm379wr"
      },
      "source": [
        "# Creation of Usul related objects\n",
        "## Definition of the UsulStroke and Usul classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r3bTE_Kw79ww",
        "colab": {}
      },
      "source": [
        "class UsulStroke:\n",
        "  def __init__(self, mnote, stroke, barduration):    \n",
        "    self.stroketype = stroke.content\n",
        "    self.duration = mnote.duration.quarterLength\n",
        "    self.offset = mnote.beat\n",
        "    self.barduration = barduration\n",
        "    self.compatoffset = float(str(float((mnote.beat - 1)/barduration))[:4])\n",
        "    if isinstance(mnote, chordclass):\n",
        "      self.hand = \"both\"\n",
        "    elif mnote.pitch.name == \"F\":\n",
        "      self.hand = \"right\"\n",
        "    elif mnote.pitch.name == \"D\":\n",
        "      self.hand = \"left\"\n",
        "    else:\n",
        "      self.hand = \"unknown\"\n",
        "\n",
        "  def __repr__(self):\n",
        "    return \"UsulStroke\"\n",
        "\n",
        "  def __str__(self):\n",
        "    return \"Stroke:%s, Duration:%s, Hand:%s, Offset:%s\" % (self.stroketype, self.duration, self.hand, self.compatoffset)\n",
        "\n",
        "class Usul:\n",
        "  def __init__(self, usulname, strokes, nbeats):\n",
        "    self.nbeats = nbeats\n",
        "    self.usul = usulname\n",
        "    self.strokes = strokes\n",
        "\n",
        "  @classmethod\n",
        "  def usul_from_file(cls, file):\n",
        "    nbeats = 0\n",
        "    score = converter.parse(file)\n",
        "    rhythm = score.getElementsByClass('Part')[0].getElementsByClass('Measure')[0]\n",
        "    notes = []\n",
        "    for element in rhythm:\n",
        "      if isinstance(element, (noteclass, chordclass)):\n",
        "        notes.append(element)\n",
        "      if isinstance(element, (tsclass)):\n",
        "        nbeats = element.beatCount\n",
        "        \n",
        "    strokes = rhythm.getElementsByClass('TextExpression')\n",
        "    usul_name = file.split('/')[-1].split('.mxl')[0].lower().replace('_', ' ')\n",
        "    strokes_list = []\n",
        "    for note in range(len(notes)):\n",
        "      strk = UsulStroke(notes[note], strokes[note], nbeats)\n",
        "      strokes_list.append(strk)\n",
        "    return cls(usul_name, strokes_list, nbeats)\n",
        "\n",
        "\n",
        "  def __iter__(self):\n",
        "    self.index = 0\n",
        "    return self\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "        return self.strokes[idx]\n",
        "\n",
        "  def __next__(self):\n",
        "    if self.index < len(self.strokes):\n",
        "      idx = self.index\n",
        "      self.index += 1\n",
        "      return self.strokes[idx]\n",
        "    else:\n",
        "      raise StopIteration\n",
        "\n",
        "  def _repr__(self):\n",
        "    return \"Usul\"\n",
        "  \n",
        "  def __str__(self):\n",
        "    return \"Usul Object: %s\" % (self.usul)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q-q72Ozi79w5"
      },
      "source": [
        "## Load all existing usuls with the classes created in last cell\n",
        "\n",
        "We load all the usuls possible (the ones for which we have the scores), into the *usul_dict* dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Z4yv3wA79w7",
        "colab": {}
      },
      "source": [
        "if IN_COLAB:\n",
        "    usuls_files_list = glob.glob('./AMPL-UPF-MSC/scores/mxl/*.mxl')\n",
        "else:\n",
        "    usuls_files_list = glob.glob('./scores/mxl/*.mxl')\n",
        "\n",
        "usuls_dict = {}\n",
        "for usul_file in usuls_files_list:\n",
        "  usul_name = usul_file.split('/')[-1].split('.mxl')[0].lower().replace('_', ' ')\n",
        "  if '\\\\' in usul_name:  # Windows use \\ instead of /\n",
        "        usul_name = usul_name.split('\\\\')[-1]\n",
        "  usuls_dict[usul_name] = Usul.usul_from_file(usul_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nPzngwqJ79xH"
      },
      "source": [
        "## Load all makams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B3sh0pIv79xJ",
        "colab": {}
      },
      "source": [
        "usuldict = {'sofyan':0,'duyek':1,'raksaksagi':2,'cenber':3,'hafif':4,'devrikebir':5,'muhammes':6,'turkaksagi':7,'oynak':8,'havi':9,'aksak':10,'yuruksemai':11,'berefsan':12,'aksaksemai':13,'fahte':14,'semai':15,'cifteduyek':16,'evfer':17}\n",
        "makamlist = ['hicaz','rast','nihavent','ussak','segah','huseyni','huzzam','mahur','kurdilihicazkar','muhayyer']\n",
        "makamdict = {makamlist[i]:i for i in range(len(makamlist))}\n",
        "\n",
        "rast = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'D5','Lead':'F4#'}\n",
        "huseyni = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'E5','Lead':'G4'}\n",
        "muhayyer = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'A5','sDom':'E5','Lead':'G4'}\n",
        "ussak = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'D5','Lead':'G4'}\n",
        "hicaz = {'A': 1, 'B':2,'C':3,'D':4,'E':5,'F':6, 'G':7,'Dom':'D5','Lead':'G4'}\n",
        "huzzam = {'B':1,'C':2,'D':3,'E':4,'F':5, 'G':6,'A':7,'Dom':'D5','Lead':'A4#'}\n",
        "kurdilihicazkar = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'G5','Lead':'F4'} \n",
        "nihavent = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'D5','Lead':'F4#'}\n",
        "segah = {'B':1,'C':2,'D':3,'E':4,'F':5, 'G':6,'A':7,'Dom':'D5','Lead':'A4#'}\n",
        "mahur = {'G': 1, 'A': 2, 'B':3,'C':4,'D':5,'E':6,'F':7,'Dom':'G5','Lead':'F4#'}\n",
        "\n",
        "if IN_COLAB:\n",
        "    folder = 'AMPL-UPF-MSC/SymbTr/txt/'\n",
        "else:\n",
        "    folder = 'SymbTr/txt/'\n",
        "\n",
        "allScores = os.listdir(folder)\n",
        "\n",
        "def getDegree(note,makam):\n",
        "    significance = None\n",
        "    degree = eval(makam)[note[0]]\n",
        "    if degree == 1:\n",
        "        significance = 'Tonic'\n",
        "    if note[:2] == eval(makam)['Dom']:\n",
        "        significance = 'Dominant'\n",
        "    if note[:2] == eval(makam)['Lead']:\n",
        "        significance = 'Leading'    \n",
        "    return degree,significance\n",
        "\n",
        "def getbars(makam,usul):\n",
        "    bars = []\n",
        "    bar = []\n",
        "    for file in allScores:\n",
        "        mak,_,us = file.split('--')[:3]\n",
        "        \n",
        "        if (mak != makam) or (us != usul):\n",
        "            continue\n",
        "        \n",
        "        with open(folder + file, encoding=\"utf8\") as scoretxt:\n",
        "            txtlines = scoretxt.read().split('\\n')\n",
        "        for i in range(2,len(txtlines)-1):\n",
        "            if int(txtlines[i].split('\\t')[1])==51: # possible usul change, leave the rest\n",
        "                break\n",
        "            if int(txtlines[i].split('\\t')[6])>0:\n",
        "                dur = int(txtlines[i].split('\\t')[6])/int(txtlines[i].split('\\t')[7])\n",
        "                notename = txtlines[i].split('\\t')[3]\n",
        "                degree, significance = getDegree(notename,mak)\n",
        "                offset = txtlines[i].split('\\t')[-1]     \n",
        "                bar.append([offset,dur,notename,degree,significance])\n",
        "                if float(offset).is_integer():\n",
        "                    bars.append(bar)\n",
        "                    bar = []\n",
        "    return bars\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K9zYK8E379xS"
      },
      "source": [
        "## Function to analyze a makam using an usul object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x4s6qrPZ79xW",
        "colab": {}
      },
      "source": [
        "def analyze_makam(makam_name, usul_name):\n",
        "    usul_part = usuldict[usul_name.replace(\"ü\", \"u\").replace(\" \", \"\").replace(\"ç\",\"c\").replace(\"ğ\",\"g\").replace(\"ş\",\"s\").replace(\"-\",\"\")]\n",
        "    makam_part = makamdict[makam_name]\n",
        "    makam = getbars(makam_name, usul_name)\n",
        "    if makam == []:\n",
        "      raise ValueError(\"Can't load makam %s-%s\" % (makam_name, usul_name))\n",
        "    usul = usuls_dict[usul_name]\n",
        "    coincidences = []\n",
        "    usul_onsets = []\n",
        "    for stroke in usul:\n",
        "        usul_onsets.append(stroke.compatoffset)  # Get the position of every stroke in this\n",
        "    onsets_indx = dict((k,i) for i,k in enumerate(usul_onsets))  # Store the index of every beat position\n",
        "    for bar in makam:\n",
        "        for note in bar:\n",
        "            beat, bar = math.modf(float(note[0]))  # Split the integer part and the decimal one\n",
        "            beat = beat - note[1]  # Substract the duration, to get the beat position\n",
        "            beat = float(str(beat)[:4])  # Limit to 4 the number of decimals\n",
        "\n",
        "            if beat in usul_onsets:\n",
        "                coinc_stroke = usul[onsets_indx[beat]]  # Get coincident stroke\n",
        "                coincidence = {'hand': coinc_stroke.hand, 'duration': coinc_stroke.duration, 'stroke': coinc_stroke.stroketype,\n",
        "                               'note_name': note[2], 'note_degree': note[3], 'note_significance': note[4], 'makam': makam_name, 'usul': usul_name}\n",
        "                coincidences.append(coincidence)\n",
        "    coincidences = pd.DataFrame(coincidences)\n",
        "    return coincidences\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wgBdQMtwEQKT"
      },
      "source": [
        "## Analyze the scores\n",
        "Analyze the scores and save them into a folder called _csv-data_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aFflfzmT_h5R",
        "outputId": "44ca7fb6-2d23-4d6e-bafe-4774edb97346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if not os.path.isdir('csv-data/'):\n",
        "  os.mkdir('csv-data/')\n",
        "import gc\n",
        "empty_ones = []\n",
        "broken_ones = []\n",
        "for usul_key in usuls_dict.keys():\n",
        "  for makam_key in makamdict.keys():\n",
        "    print(\"Analizing %s-%s\" % (usul_key, makam_key))\n",
        "    try:\n",
        "      results = analyze_makam(makam_key, usul_key)\n",
        "    except ValueError:\n",
        "      broken_ones.append(\"%s, %s\" % (makam_key, usul_key))\n",
        "    if not results.empty:\n",
        "      results.to_csv('csv-data/%s-%s.csv' % (usul_key, makam_key))\n",
        "      print(\"\\tAnalyzed %s-%s\" % (usul_key, makam_key))\n",
        "    else:\n",
        "      print(\"\\tEmpty: \", usul_key, makam_key)\n",
        "      empty_ones.append(\"%s-%s\" % (usul_key, makam_key))\n",
        "  gc.collect()\n",
        "with open('csv-data/empty_ones.txt', 'w', encoding=\"utf8\") as file:\n",
        "  for empty in empty_ones:\n",
        "    file.write(\"%s\\n\" % empty)\n",
        "with open('csv-data/broken_ones.txt', 'w', encoding=\"utf8\") as file:\n",
        "  for broken in broken_ones:\n",
        "    file.write(\"%s\\n\" % broken)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analizing türk aksaği-hicaz\n",
            "\tAnalyzed türk aksaği-hicaz\n",
            "Analizing türk aksaği-rast\n",
            "\tAnalyzed türk aksaği-rast\n",
            "Analizing türk aksaği-nihavent\n",
            "\tAnalyzed türk aksaği-nihavent\n",
            "Analizing türk aksaği-ussak\n",
            "\tAnalyzed türk aksaği-ussak\n",
            "Analizing türk aksaği-segah\n",
            "\tAnalyzed türk aksaği-segah\n",
            "Analizing türk aksaği-huseyni\n",
            "\tAnalyzed türk aksaği-huseyni\n",
            "Analizing türk aksaği-huzzam\n",
            "\tAnalyzed türk aksaği-huzzam\n",
            "Analizing türk aksaği-mahur\n",
            "\tAnalyzed türk aksaği-mahur\n",
            "Analizing türk aksaği-kurdilihicazkar\n",
            "\tAnalyzed türk aksaği-kurdilihicazkar\n",
            "Analizing türk aksaği-muhayyer\n",
            "\tAnalyzed türk aksaği-muhayyer\n",
            "Analizing çifte düyek-hicaz\n",
            "\tAnalyzed çifte düyek-hicaz\n",
            "Analizing çifte düyek-rast\n",
            "\tAnalyzed çifte düyek-rast\n",
            "Analizing çifte düyek-nihavent\n",
            "\tAnalyzed çifte düyek-nihavent\n",
            "Analizing çifte düyek-ussak\n",
            "\tAnalyzed çifte düyek-ussak\n",
            "Analizing çifte düyek-segah\n",
            "\tAnalyzed çifte düyek-segah\n",
            "Analizing çifte düyek-huseyni\n",
            "\tAnalyzed çifte düyek-huseyni\n",
            "Analizing çifte düyek-huzzam\n",
            "\tAnalyzed çifte düyek-huzzam\n",
            "Analizing çifte düyek-mahur\n",
            "\tAnalyzed çifte düyek-mahur\n",
            "Analizing çifte düyek-kurdilihicazkar\n",
            "\tAnalyzed çifte düyek-kurdilihicazkar\n",
            "Analizing çifte düyek-muhayyer\n",
            "\tAnalyzed çifte düyek-muhayyer\n",
            "Analizing semai-hicaz\n",
            "\tAnalyzed semai-hicaz\n",
            "Analizing semai-rast\n",
            "\tEmpty:  semai rast\n",
            "Analizing semai-nihavent\n",
            "\tAnalyzed semai-nihavent\n",
            "Analizing semai-ussak\n",
            "\tEmpty:  semai ussak\n",
            "Analizing semai-segah\n",
            "\tAnalyzed semai-segah\n",
            "Analizing semai-huseyni\n",
            "\tEmpty:  semai huseyni\n",
            "Analizing semai-huzzam\n",
            "\tEmpty:  semai huzzam\n",
            "Analizing semai-mahur\n",
            "\tEmpty:  semai mahur\n",
            "Analizing semai-kurdilihicazkar\n",
            "\tEmpty:  semai kurdilihicazkar\n",
            "Analizing semai-muhayyer\n",
            "\tEmpty:  semai muhayyer\n",
            "Analizing evfer-hicaz\n",
            "\tAnalyzed evfer-hicaz\n",
            "Analizing evfer-rast\n",
            "\tAnalyzed evfer-rast\n",
            "Analizing evfer-nihavent\n",
            "\tAnalyzed evfer-nihavent\n",
            "Analizing evfer-ussak\n",
            "\tAnalyzed evfer-ussak\n",
            "Analizing evfer-segah\n",
            "\tAnalyzed evfer-segah\n",
            "Analizing evfer-huseyni\n",
            "\tAnalyzed evfer-huseyni\n",
            "Analizing evfer-huzzam\n",
            "\tAnalyzed evfer-huzzam\n",
            "Analizing evfer-mahur\n",
            "\tAnalyzed evfer-mahur\n",
            "Analizing evfer-kurdilihicazkar\n",
            "\tAnalyzed evfer-kurdilihicazkar\n",
            "Analizing evfer-muhayyer\n",
            "\tAnalyzed evfer-muhayyer\n",
            "Analizing havi-hicaz\n",
            "\tAnalyzed havi-hicaz\n",
            "Analizing havi-rast\n",
            "\tAnalyzed havi-rast\n",
            "Analizing havi-nihavent\n",
            "\tAnalyzed havi-nihavent\n",
            "Analizing havi-ussak\n",
            "\tAnalyzed havi-ussak\n",
            "Analizing havi-segah\n",
            "\tAnalyzed havi-segah\n",
            "Analizing havi-huseyni\n",
            "\tAnalyzed havi-huseyni\n",
            "Analizing havi-huzzam\n",
            "\tAnalyzed havi-huzzam\n",
            "Analizing havi-mahur\n",
            "\tAnalyzed havi-mahur\n",
            "Analizing havi-kurdilihicazkar\n",
            "\tAnalyzed havi-kurdilihicazkar\n",
            "Analizing havi-muhayyer\n",
            "\tAnalyzed havi-muhayyer\n",
            "Analizing hafif-hicaz\n",
            "\tAnalyzed hafif-hicaz\n",
            "Analizing hafif-rast\n",
            "\tAnalyzed hafif-rast\n",
            "Analizing hafif-nihavent\n",
            "\tAnalyzed hafif-nihavent\n",
            "Analizing hafif-ussak\n",
            "\tAnalyzed hafif-ussak\n",
            "Analizing hafif-segah\n",
            "\tAnalyzed hafif-segah\n",
            "Analizing hafif-huseyni\n",
            "\tAnalyzed hafif-huseyni\n",
            "Analizing hafif-huzzam\n",
            "\tAnalyzed hafif-huzzam\n",
            "Analizing hafif-mahur\n",
            "\tAnalyzed hafif-mahur\n",
            "Analizing hafif-kurdilihicazkar\n",
            "\tAnalyzed hafif-kurdilihicazkar\n",
            "Analizing hafif-muhayyer\n",
            "\tAnalyzed hafif-muhayyer\n",
            "Analizing aksak semai-hicaz\n",
            "\tAnalyzed aksak semai-hicaz\n",
            "Analizing aksak semai-rast\n",
            "\tAnalyzed aksak semai-rast\n",
            "Analizing aksak semai-nihavent\n",
            "\tAnalyzed aksak semai-nihavent\n",
            "Analizing aksak semai-ussak\n",
            "\tAnalyzed aksak semai-ussak\n",
            "Analizing aksak semai-segah\n",
            "\tAnalyzed aksak semai-segah\n",
            "Analizing aksak semai-huseyni\n",
            "\tAnalyzed aksak semai-huseyni\n",
            "Analizing aksak semai-huzzam\n",
            "\tAnalyzed aksak semai-huzzam\n",
            "Analizing aksak semai-mahur\n",
            "\tAnalyzed aksak semai-mahur\n",
            "Analizing aksak semai-kurdilihicazkar\n",
            "\tAnalyzed aksak semai-kurdilihicazkar\n",
            "Analizing aksak semai-muhayyer\n",
            "\tAnalyzed aksak semai-muhayyer\n",
            "Analizing aksak-hicaz\n",
            "\tAnalyzed aksak-hicaz\n",
            "Analizing aksak-rast\n",
            "\tAnalyzed aksak-rast\n",
            "Analizing aksak-nihavent\n",
            "\tAnalyzed aksak-nihavent\n",
            "Analizing aksak-ussak\n",
            "\tAnalyzed aksak-ussak\n",
            "Analizing aksak-segah\n",
            "\tAnalyzed aksak-segah\n",
            "Analizing aksak-huseyni\n",
            "\tAnalyzed aksak-huseyni\n",
            "Analizing aksak-huzzam\n",
            "\tAnalyzed aksak-huzzam\n",
            "Analizing aksak-mahur\n",
            "\tAnalyzed aksak-mahur\n",
            "Analizing aksak-kurdilihicazkar\n",
            "\tAnalyzed aksak-kurdilihicazkar\n",
            "Analizing aksak-muhayyer\n",
            "\tAnalyzed aksak-muhayyer\n",
            "Analizing düyek-hicaz\n",
            "\tAnalyzed düyek-hicaz\n",
            "Analizing düyek-rast\n",
            "\tAnalyzed düyek-rast\n",
            "Analizing düyek-nihavent\n",
            "\tAnalyzed düyek-nihavent\n",
            "Analizing düyek-ussak\n",
            "\tAnalyzed düyek-ussak\n",
            "Analizing düyek-segah\n",
            "\tAnalyzed düyek-segah\n",
            "Analizing düyek-huseyni\n",
            "\tAnalyzed düyek-huseyni\n",
            "Analizing düyek-huzzam\n",
            "\tAnalyzed düyek-huzzam\n",
            "Analizing düyek-mahur\n",
            "\tAnalyzed düyek-mahur\n",
            "Analizing düyek-kurdilihicazkar\n",
            "\tAnalyzed düyek-kurdilihicazkar\n",
            "Analizing düyek-muhayyer\n",
            "\tAnalyzed düyek-muhayyer\n",
            "Analizing muhammes-hicaz\n",
            "\tAnalyzed muhammes-hicaz\n",
            "Analizing muhammes-rast\n",
            "\tAnalyzed muhammes-rast\n",
            "Analizing muhammes-nihavent\n",
            "\tAnalyzed muhammes-nihavent\n",
            "Analizing muhammes-ussak\n",
            "\tAnalyzed muhammes-ussak\n",
            "Analizing muhammes-segah\n",
            "\tAnalyzed muhammes-segah\n",
            "Analizing muhammes-huseyni\n",
            "\tAnalyzed muhammes-huseyni\n",
            "Analizing muhammes-huzzam\n",
            "\tAnalyzed muhammes-huzzam\n",
            "Analizing muhammes-mahur\n",
            "\tAnalyzed muhammes-mahur\n",
            "Analizing muhammes-kurdilihicazkar\n",
            "\tAnalyzed muhammes-kurdilihicazkar\n",
            "Analizing muhammes-muhayyer\n",
            "\tAnalyzed muhammes-muhayyer\n",
            "Analizing sofyan-hicaz\n",
            "\tAnalyzed sofyan-hicaz\n",
            "Analizing sofyan-rast\n",
            "\tAnalyzed sofyan-rast\n",
            "Analizing sofyan-nihavent\n",
            "\tAnalyzed sofyan-nihavent\n",
            "Analizing sofyan-ussak\n",
            "\tAnalyzed sofyan-ussak\n",
            "Analizing sofyan-segah\n",
            "\tAnalyzed sofyan-segah\n",
            "Analizing sofyan-huseyni\n",
            "\tAnalyzed sofyan-huseyni\n",
            "Analizing sofyan-huzzam\n",
            "\tAnalyzed sofyan-huzzam\n",
            "Analizing sofyan-mahur\n",
            "\tAnalyzed sofyan-mahur\n",
            "Analizing sofyan-kurdilihicazkar\n",
            "\tAnalyzed sofyan-kurdilihicazkar\n",
            "Analizing sofyan-muhayyer\n",
            "\tAnalyzed sofyan-muhayyer\n",
            "Analizing çenber-hicaz\n",
            "\tAnalyzed çenber-hicaz\n",
            "Analizing çenber-rast\n",
            "\tAnalyzed çenber-rast\n",
            "Analizing çenber-nihavent\n",
            "\tAnalyzed çenber-nihavent\n",
            "Analizing çenber-ussak\n",
            "\tAnalyzed çenber-ussak\n",
            "Analizing çenber-segah\n",
            "\tAnalyzed çenber-segah\n",
            "Analizing çenber-huseyni\n",
            "\tAnalyzed çenber-huseyni\n",
            "Analizing çenber-huzzam\n",
            "\tAnalyzed çenber-huzzam\n",
            "Analizing çenber-mahur\n",
            "\tAnalyzed çenber-mahur\n",
            "Analizing çenber-kurdilihicazkar\n",
            "\tAnalyzed çenber-kurdilihicazkar\n",
            "Analizing çenber-muhayyer\n",
            "\tAnalyzed çenber-muhayyer\n",
            "Analizing berefşan-hicaz\n",
            "\tAnalyzed berefşan-hicaz\n",
            "Analizing berefşan-rast\n",
            "\tAnalyzed berefşan-rast\n",
            "Analizing berefşan-nihavent\n",
            "\tAnalyzed berefşan-nihavent\n",
            "Analizing berefşan-ussak\n",
            "\tAnalyzed berefşan-ussak\n",
            "Analizing berefşan-segah\n",
            "\tAnalyzed berefşan-segah\n",
            "Analizing berefşan-huseyni\n",
            "\tAnalyzed berefşan-huseyni\n",
            "Analizing berefşan-huzzam\n",
            "\tAnalyzed berefşan-huzzam\n",
            "Analizing berefşan-mahur\n",
            "\tAnalyzed berefşan-mahur\n",
            "Analizing berefşan-kurdilihicazkar\n",
            "\tAnalyzed berefşan-kurdilihicazkar\n",
            "Analizing berefşan-muhayyer\n",
            "\tAnalyzed berefşan-muhayyer\n",
            "Analizing fahte-hicaz\n",
            "\tAnalyzed fahte-hicaz\n",
            "Analizing fahte-rast\n",
            "\tAnalyzed fahte-rast\n",
            "Analizing fahte-nihavent\n",
            "\tAnalyzed fahte-nihavent\n",
            "Analizing fahte-ussak\n",
            "\tAnalyzed fahte-ussak\n",
            "Analizing fahte-segah\n",
            "\tAnalyzed fahte-segah\n",
            "Analizing fahte-huseyni\n",
            "\tAnalyzed fahte-huseyni\n",
            "Analizing fahte-huzzam\n",
            "\tAnalyzed fahte-huzzam\n",
            "Analizing fahte-mahur\n",
            "\tAnalyzed fahte-mahur\n",
            "Analizing fahte-kurdilihicazkar\n",
            "\tAnalyzed fahte-kurdilihicazkar\n",
            "Analizing fahte-muhayyer\n",
            "\tAnalyzed fahte-muhayyer\n",
            "Analizing raks aksaği-hicaz\n",
            "\tAnalyzed raks aksaği-hicaz\n",
            "Analizing raks aksaği-rast\n",
            "\tAnalyzed raks aksaği-rast\n",
            "Analizing raks aksaği-nihavent\n",
            "\tAnalyzed raks aksaği-nihavent\n",
            "Analizing raks aksaği-ussak\n",
            "\tAnalyzed raks aksaği-ussak\n",
            "Analizing raks aksaği-segah\n",
            "\tAnalyzed raks aksaği-segah\n",
            "Analizing raks aksaği-huseyni\n",
            "\tAnalyzed raks aksaği-huseyni\n",
            "Analizing raks aksaği-huzzam\n",
            "\tAnalyzed raks aksaği-huzzam\n",
            "Analizing raks aksaği-mahur\n",
            "\tAnalyzed raks aksaği-mahur\n",
            "Analizing raks aksaği-kurdilihicazkar\n",
            "\tAnalyzed raks aksaği-kurdilihicazkar\n",
            "Analizing raks aksaği-muhayyer\n",
            "\tAnalyzed raks aksaği-muhayyer\n",
            "Analizing yürük semai-hicaz\n",
            "\tAnalyzed yürük semai-hicaz\n",
            "Analizing yürük semai-rast\n",
            "\tAnalyzed yürük semai-rast\n",
            "Analizing yürük semai-nihavent\n",
            "\tAnalyzed yürük semai-nihavent\n",
            "Analizing yürük semai-ussak\n",
            "\tAnalyzed yürük semai-ussak\n",
            "Analizing yürük semai-segah\n",
            "\tAnalyzed yürük semai-segah\n",
            "Analizing yürük semai-huseyni\n",
            "\tAnalyzed yürük semai-huseyni\n",
            "Analizing yürük semai-huzzam\n",
            "\tAnalyzed yürük semai-huzzam\n",
            "Analizing yürük semai-mahur\n",
            "\tAnalyzed yürük semai-mahur\n",
            "Analizing yürük semai-kurdilihicazkar\n",
            "\tAnalyzed yürük semai-kurdilihicazkar\n",
            "Analizing yürük semai-muhayyer\n",
            "\tAnalyzed yürük semai-muhayyer\n",
            "Analizing devr-i kebir-hicaz\n",
            "\tAnalyzed devr-i kebir-hicaz\n",
            "Analizing devr-i kebir-rast\n",
            "\tAnalyzed devr-i kebir-rast\n",
            "Analizing devr-i kebir-nihavent\n",
            "\tAnalyzed devr-i kebir-nihavent\n",
            "Analizing devr-i kebir-ussak\n",
            "\tAnalyzed devr-i kebir-ussak\n",
            "Analizing devr-i kebir-segah\n",
            "\tAnalyzed devr-i kebir-segah\n",
            "Analizing devr-i kebir-huseyni\n",
            "\tAnalyzed devr-i kebir-huseyni\n",
            "Analizing devr-i kebir-huzzam\n",
            "\tAnalyzed devr-i kebir-huzzam\n",
            "Analizing devr-i kebir-mahur\n",
            "\tAnalyzed devr-i kebir-mahur\n",
            "Analizing devr-i kebir-kurdilihicazkar\n",
            "\tAnalyzed devr-i kebir-kurdilihicazkar\n",
            "Analizing devr-i kebir-muhayyer\n",
            "\tAnalyzed devr-i kebir-muhayyer\n",
            "Analizing oynak-hicaz\n",
            "\tAnalyzed oynak-hicaz\n",
            "Analizing oynak-rast\n",
            "\tAnalyzed oynak-rast\n",
            "Analizing oynak-nihavent\n",
            "\tAnalyzed oynak-nihavent\n",
            "Analizing oynak-ussak\n",
            "\tAnalyzed oynak-ussak\n",
            "Analizing oynak-segah\n",
            "\tAnalyzed oynak-segah\n",
            "Analizing oynak-huseyni\n",
            "\tAnalyzed oynak-huseyni\n",
            "Analizing oynak-huzzam\n",
            "\tAnalyzed oynak-huzzam\n",
            "Analizing oynak-mahur\n",
            "\tAnalyzed oynak-mahur\n",
            "Analizing oynak-kurdilihicazkar\n",
            "\tAnalyzed oynak-kurdilihicazkar\n",
            "Analizing oynak-muhayyer\n",
            "\tAnalyzed oynak-muhayyer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIFHiVjaWMyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}